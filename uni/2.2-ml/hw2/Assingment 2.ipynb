{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Instructions\n",
    "- Your submission should be the `.ipynb` file with your name,\n",
    "  like `FirstnameLastname.ipynb`. it should include the answers to the questions in\n",
    "  markdown cells.\n",
    "- You are expected to follow the best practices for code writing and model\n",
    "training. Poor coding style will be penalized.\n",
    "- You are allowed to discuss ideas with your peers, but no sharing of code.\n",
    "Plagiarism in the code will result in failing. If you use code from the\n",
    "internet, cite it by adding the source of the code as a comment in the first line of the code cell.\n",
    "- In real life clients can give unclear goals or requirements. So, if the instructions seem vague, use common sense to make reasonable assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: [Where's Waldo?](https://www.wikihow.com/Find-Waldo) (35 points)\n",
    "\n",
    "## Fingerprinting\n",
    "Browser fingerprinting is a technique used to identify and track individuals based on unique characteristics of their web browser configuration. These characteristics can include the browser type, version, installed plugins, and screen resolution, among others. By combining these attributes, websites can create a digital fingerprint that can be used to track user behavior across multiple sites, even if they clear their cookies or use different devices. This has raised concerns about privacy and the potential for this technology to be used for targeted advertising, surveillance, and other purposes.\n",
    "\n",
    "[Read more]([Fingerprinting](https://datadome.co/learning-center/browser-fingerprinting-techniques/))\n",
    "\n",
    "##  What you need to do\n",
    "For this task, you are required to build a fully connect feed-forward ANN model\n",
    "for a classification problem.\n",
    "\n",
    "For the given data, you need do proper data preprocessing, data analysis,\n",
    "design the ANN model, then fine-tune your model architecture.\n",
    "\n",
    "For evaluating your model, do $ 80/20 $ train test split.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Select and implement suitable data preprocessing techniques. 10%\n",
    "- Identify the appropriate classification approach for a given problem. 20%\n",
    "- Apply ANNs to solve a classification problem (basic training, validation, testing -- without fine tuning). 50%\n",
    "- Fine-tune to determine the optimal model architecture. 20%\n",
    "\n",
    "\n",
    "### Data\n",
    "You will be working with the data in `Task_1.csv` for identifying waldo (the user with `user_id=0`) \n",
    "\n",
    "The columns include:\n",
    " - browser\n",
    " - os\n",
    " - locale\n",
    " - user_id\n",
    " - location\n",
    " - sites\n",
    " - time\n",
    " - date\n",
    "\n",
    "After training, evaluate you model by print [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
    "on your test set. \n",
    "\n",
    "Then predicting each user in `task_1_verify.csv` whether it's Waldo or not. Your output should look like the following:\n",
    "\n",
    "`row_idx: is_waldo`, notice if the user is waldo your output should be 1\n",
    "\n",
    "``` \n",
    "0: 1\n",
    "1: 0\n",
    "2: 0\n",
    "3: 1\n",
    "4: 1\n",
    "...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T14:54:36.795534Z",
     "start_time": "2023-04-11T14:54:36.712029Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import Recall, Precision\n",
    "import keras.backend as K\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "RANDOM_STATE = 123\n",
    "VERBOSITY = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:05:55.107280Z",
     "start_time": "2023-04-11T15:05:53.660911Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      "Encoding...\n",
      "Index(['browser', 'os', 'locale', 'location', 'time', 'date'], dtype='object')\n",
      "Completed encoding\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_y(df):\n",
    "    y = df.pop(\"user_id\")\n",
    "    y = y.apply(lambda x: 1 if x == 0 else 0)\n",
    "    y = pd.DataFrame(y)\n",
    "\n",
    "    return y\n",
    "\n",
    "def preprocess_X(df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):\n",
    "    def scale_col(col: pd.Series) -> pd.Series:\n",
    "        from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        col_2d = col.values.reshape(-1, 1)\n",
    "        scaled_col = scaler.fit_transform(col_2d)\n",
    "        return scaled_col.reshape(-1)\n",
    "\n",
    "\n",
    "    # Convert \"time\" column to float, and scale it\n",
    "    time_float = pd.to_timedelta(df[\"time\"])\n",
    "    time_float = scale_col(time_float)\n",
    "    df[\"time\"] = time_float\n",
    "\n",
    "    # Convert \"date\" column to int, and scale it\n",
    "    date_int = df[\"date\"].apply(lambda x: datetime.date.fromisoformat(x).toordinal())\n",
    "    date_int = scale_col(date_int)\n",
    "    df[\"date\"] = date_int\n",
    "\n",
    "    cols_to_drop = [\n",
    "        # \"time\",\n",
    "        # \"date\",\n",
    "        \"sites\"\n",
    "    ]\n",
    "    X = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    if \"index\" in X.columns:\n",
    "        X = X.drop(columns=[\"index\"])\n",
    "\n",
    "    return X\n",
    "\n",
    "def preprocess(fpath: str, with_y=True):\n",
    "    df = pd.read_csv(fpath)\n",
    "\n",
    "    if with_y:\n",
    "        y = preprocess_y(df)\n",
    "        X = preprocess_X(df)\n",
    "        return X, y\n",
    "    else:\n",
    "        X = preprocess_X(df)\n",
    "        return X\n",
    "\n",
    "def onehot_encode(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(X.columns)\n",
    "\n",
    "    X_skip = X[[\"date\", \"time\"]]\n",
    "    encode_cols=[\"browser\", \"os\", \"locale\", \"location\"]\n",
    "    X_encode = X[encode_cols]\n",
    "\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(X_encode)\n",
    "    np_array = encoder.transform(X_encode).toarray()\n",
    "    feat_columns = encoder.get_feature_names_out(encode_cols)\n",
    "\n",
    "    res_df = pd.DataFrame(np_array, columns=feat_columns)\n",
    "\n",
    "    return res_df.assign(**{\"time\": X_skip[\"time\"], \"date\": X_skip[\"date\"]})\n",
    "    # return pd.concat([res_df, X_skip], axis=0, ignore_index=True)\n",
    "\n",
    "print(\"Preprocessing...\")\n",
    "X, y = preprocess(\"task1.csv\")\n",
    "\n",
    "print(\"Encoding...\")\n",
    "\n",
    "X = onehot_encode(X)\n",
    "X_df_columns = X.columns  # will be needed further\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Completed encoding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:06:00.225384Z",
     "start_time": "2023-04-11T15:06:00.107869Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16320, 58), (4081, 58))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:06:05.157045Z",
     "start_time": "2023-04-11T15:06:04.946377Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def my_f1_score(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "\n",
    "def build_model(neurons_cnt=16, layers_cnt=1, dropout_prob=0.5):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons_cnt, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dropout(dropout_prob))\n",
    "\n",
    "    for i in range(layers_cnt):\n",
    "        model.add(Dense(neurons_cnt, activation='relu'))\n",
    "        model.add(Dropout(dropout_prob))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        my_f1_score,\n",
    "        'accuracy',\n",
    "        Precision(),\n",
    "        Recall(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:07:09.215307Z",
     "start_time": "2023-04-11T15:06:16.300965Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.fit\n",
      "Epoch 1/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0043 - my_f1_score: 0.8992 - accuracy: 0.9990 - precision_1: 0.9802 - recall_1: 0.9688 - val_loss: 0.0052 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 2/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0049 - my_f1_score: 0.8793 - accuracy: 0.9991 - precision_1: 0.9586 - recall_1: 0.9961 - val_loss: 0.0049 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 3/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0054 - my_f1_score: 0.8886 - accuracy: 0.9988 - precision_1: 0.9651 - recall_1: 0.9727 - val_loss: 0.0052 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 4/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0037 - my_f1_score: 0.8824 - accuracy: 0.9991 - precision_1: 0.9729 - recall_1: 0.9805 - val_loss: 0.0051 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 5/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0039 - my_f1_score: 0.8662 - accuracy: 0.9991 - precision_1: 0.9729 - recall_1: 0.9805 - val_loss: 0.0053 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 6/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0038 - my_f1_score: 0.8711 - accuracy: 0.9992 - precision_1: 0.9693 - recall_1: 0.9883 - val_loss: 0.0048 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 7/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0059 - my_f1_score: 0.8447 - accuracy: 0.9985 - precision_1: 0.9611 - recall_1: 0.9648 - val_loss: 0.0046 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 8/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0057 - my_f1_score: 0.8686 - accuracy: 0.9985 - precision_1: 0.9575 - recall_1: 0.9688 - val_loss: 0.0044 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 9/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0065 - my_f1_score: 0.8703 - accuracy: 0.9982 - precision_1: 0.9605 - recall_1: 0.9492 - val_loss: 0.0047 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 10/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0044 - my_f1_score: 0.9023 - accuracy: 0.9988 - precision_1: 0.9651 - recall_1: 0.9727 - val_loss: 0.0049 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 11/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0050 - my_f1_score: 0.8565 - accuracy: 0.9988 - precision_1: 0.9724 - recall_1: 0.9648 - val_loss: 0.0050 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 12/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0049 - my_f1_score: 0.8672 - accuracy: 0.9986 - precision_1: 0.9648 - recall_1: 0.9648 - val_loss: 0.0048 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 13/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0063 - my_f1_score: 0.9113 - accuracy: 0.9984 - precision_1: 0.9502 - recall_1: 0.9688 - val_loss: 0.0050 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 14/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0043 - my_f1_score: 0.9071 - accuracy: 0.9990 - precision_1: 0.9765 - recall_1: 0.9727 - val_loss: 0.0050 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 15/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0035 - my_f1_score: 0.9211 - accuracy: 0.9992 - precision_1: 0.9842 - recall_1: 0.9727 - val_loss: 0.0055 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 16/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0055 - my_f1_score: 0.9309 - accuracy: 0.9991 - precision_1: 0.9692 - recall_1: 0.9844 - val_loss: 0.0055 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 17/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0046 - my_f1_score: 0.8577 - accuracy: 0.9990 - precision_1: 0.9691 - recall_1: 0.9805 - val_loss: 0.0055 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 18/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0042 - my_f1_score: 0.8730 - accuracy: 0.9989 - precision_1: 0.9689 - recall_1: 0.9727 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 19/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0050 - my_f1_score: 0.8524 - accuracy: 0.9990 - precision_1: 0.9728 - recall_1: 0.9766 - val_loss: 0.0051 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 20/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0047 - my_f1_score: 0.8733 - accuracy: 0.9992 - precision_1: 0.9693 - recall_1: 0.9883 - val_loss: 0.0054 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 21/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0050 - my_f1_score: 0.8919 - accuracy: 0.9990 - precision_1: 0.9620 - recall_1: 0.9883 - val_loss: 0.0049 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 22/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0044 - my_f1_score: 0.8689 - accuracy: 0.9989 - precision_1: 0.9727 - recall_1: 0.9727 - val_loss: 0.0048 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 23/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0042 - my_f1_score: 0.8621 - accuracy: 0.9989 - precision_1: 0.9764 - recall_1: 0.9688 - val_loss: 0.0058 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 24/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0046 - my_f1_score: 0.8839 - accuracy: 0.9986 - precision_1: 0.9685 - recall_1: 0.9609 - val_loss: 0.0058 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 25/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0054 - my_f1_score: 0.8570 - accuracy: 0.9985 - precision_1: 0.9575 - recall_1: 0.9688 - val_loss: 0.0046 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 26/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0040 - my_f1_score: 0.9228 - accuracy: 0.9991 - precision_1: 0.9692 - recall_1: 0.9844 - val_loss: 0.0047 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 27/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0046 - my_f1_score: 0.8916 - accuracy: 0.9988 - precision_1: 0.9688 - recall_1: 0.9688 - val_loss: 0.0048 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 28/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0041 - my_f1_score: 0.9406 - accuracy: 0.9990 - precision_1: 0.9691 - recall_1: 0.9805 - val_loss: 0.0051 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 29/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0054 - my_f1_score: 0.9006 - accuracy: 0.9987 - precision_1: 0.9650 - recall_1: 0.9688 - val_loss: 0.0052 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0040 - my_f1_score: 0.9020 - accuracy: 0.9987 - precision_1: 0.9799 - recall_1: 0.9531 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 31/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0046 - my_f1_score: 0.9034 - accuracy: 0.9991 - precision_1: 0.9766 - recall_1: 0.9766 - val_loss: 0.0054 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 32/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0038 - my_f1_score: 0.8858 - accuracy: 0.9990 - precision_1: 0.9802 - recall_1: 0.9688 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 33/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0042 - my_f1_score: 0.8752 - accuracy: 0.9990 - precision_1: 0.9691 - recall_1: 0.9805 - val_loss: 0.0056 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 34/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0057 - my_f1_score: 0.8966 - accuracy: 0.9987 - precision_1: 0.9476 - recall_1: 0.9883 - val_loss: 0.0054 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 35/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0046 - my_f1_score: 0.9051 - accuracy: 0.9988 - precision_1: 0.9688 - recall_1: 0.9688 - val_loss: 0.0054 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 36/200\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0048 - my_f1_score: 0.8844 - accuracy: 0.9989 - precision_1: 0.9654 - recall_1: 0.9805 - val_loss: 0.0056 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 37/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0042 - my_f1_score: 0.8981 - accuracy: 0.9989 - precision_1: 0.9689 - recall_1: 0.9727 - val_loss: 0.0049 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 38/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0039 - my_f1_score: 0.9009 - accuracy: 0.9992 - precision_1: 0.9804 - recall_1: 0.9766 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 39/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0061 - my_f1_score: 0.8189 - accuracy: 0.9982 - precision_1: 0.9605 - recall_1: 0.9492 - val_loss: 0.0053 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 40/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0047 - my_f1_score: 0.8782 - accuracy: 0.9986 - precision_1: 0.9722 - recall_1: 0.9570 - val_loss: 0.0055 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 41/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0046 - my_f1_score: 0.9070 - accuracy: 0.9986 - precision_1: 0.9542 - recall_1: 0.9766 - val_loss: 0.0055 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 42/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0041 - my_f1_score: 0.9214 - accuracy: 0.9992 - precision_1: 0.9767 - recall_1: 0.9844 - val_loss: 0.0056 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 43/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0052 - my_f1_score: 0.8975 - accuracy: 0.9985 - precision_1: 0.9684 - recall_1: 0.9570 - val_loss: 0.0056 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 44/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0053 - my_f1_score: 0.8333 - accuracy: 0.9984 - precision_1: 0.9572 - recall_1: 0.9609 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 45/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0054 - my_f1_score: 0.8896 - accuracy: 0.9984 - precision_1: 0.9608 - recall_1: 0.9570 - val_loss: 0.0055 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 46/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0055 - my_f1_score: 0.8851 - accuracy: 0.9988 - precision_1: 0.9651 - recall_1: 0.9727 - val_loss: 0.0053 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 47/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0051 - my_f1_score: 0.9152 - accuracy: 0.9983 - precision_1: 0.9643 - recall_1: 0.9492 - val_loss: 0.0054 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 48/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0042 - my_f1_score: 0.8919 - accuracy: 0.9985 - precision_1: 0.9797 - recall_1: 0.9414 - val_loss: 0.0051 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 49/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0050 - my_f1_score: 0.8849 - accuracy: 0.9987 - precision_1: 0.9614 - recall_1: 0.9727 - val_loss: 0.0049 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 50/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0040 - my_f1_score: 0.8908 - accuracy: 0.9990 - precision_1: 0.9691 - recall_1: 0.9805 - val_loss: 0.0055 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 51/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0045 - my_f1_score: 0.9167 - accuracy: 0.9989 - precision_1: 0.9690 - recall_1: 0.9766 - val_loss: 0.0058 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 52/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0039 - my_f1_score: 0.9187 - accuracy: 0.9989 - precision_1: 0.9802 - recall_1: 0.9648 - val_loss: 0.0058 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 53/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0043 - my_f1_score: 0.8889 - accuracy: 0.9989 - precision_1: 0.9653 - recall_1: 0.9766 - val_loss: 0.0056 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 54/200\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0052 - my_f1_score: 0.8859 - accuracy: 0.9987 - precision_1: 0.9614 - recall_1: 0.9727 - val_loss: 0.0053 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 55/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0048 - my_f1_score: 0.9058 - accuracy: 0.9985 - precision_1: 0.9646 - recall_1: 0.9570 - val_loss: 0.0053 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 56/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0052 - my_f1_score: 0.8679 - accuracy: 0.9987 - precision_1: 0.9579 - recall_1: 0.9766 - val_loss: 0.0052 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 57/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0048 - my_f1_score: 0.8961 - accuracy: 0.9985 - precision_1: 0.9683 - recall_1: 0.9531 - val_loss: 0.0054 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 58/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0051 - my_f1_score: 0.8996 - accuracy: 0.9987 - precision_1: 0.9614 - recall_1: 0.9727 - val_loss: 0.0050 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0055 - my_f1_score: 0.8765 - accuracy: 0.9989 - precision_1: 0.9689 - recall_1: 0.9727 - val_loss: 0.0052 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 60/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0039 - my_f1_score: 0.9193 - accuracy: 0.9989 - precision_1: 0.9763 - recall_1: 0.9648 - val_loss: 0.0053 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 61/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0053 - my_f1_score: 0.9029 - accuracy: 0.9989 - precision_1: 0.9689 - recall_1: 0.9727 - val_loss: 0.0055 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 62/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0039 - my_f1_score: 0.8772 - accuracy: 0.9991 - precision_1: 0.9803 - recall_1: 0.9727 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 63/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0048 - my_f1_score: 0.8911 - accuracy: 0.9989 - precision_1: 0.9618 - recall_1: 0.9844 - val_loss: 0.0053 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 64/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0066 - my_f1_score: 0.8548 - accuracy: 0.9985 - precision_1: 0.9574 - recall_1: 0.9648 - val_loss: 0.0050 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 65/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0029 - my_f1_score: 0.9364 - accuracy: 0.9993 - precision_1: 0.9960 - recall_1: 0.9688 - val_loss: 0.0052 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 66/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0051 - my_f1_score: 0.8463 - accuracy: 0.9984 - precision_1: 0.9644 - recall_1: 0.9531 - val_loss: 0.0053 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 67/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0049 - my_f1_score: 0.9267 - accuracy: 0.9992 - precision_1: 0.9767 - recall_1: 0.9805 - val_loss: 0.0052 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 68/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0043 - my_f1_score: 0.8980 - accuracy: 0.9990 - precision_1: 0.9728 - recall_1: 0.9766 - val_loss: 0.0054 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 69/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0050 - my_f1_score: 0.8742 - accuracy: 0.9989 - precision_1: 0.9690 - recall_1: 0.9766 - val_loss: 0.0049 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 70/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0041 - my_f1_score: 0.8910 - accuracy: 0.9990 - precision_1: 0.9728 - recall_1: 0.9766 - val_loss: 0.0051 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 71/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0049 - my_f1_score: 0.8733 - accuracy: 0.9985 - precision_1: 0.9683 - recall_1: 0.9531 - val_loss: 0.0056 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 72/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0053 - my_f1_score: 0.8840 - accuracy: 0.9987 - precision_1: 0.9686 - recall_1: 0.9648 - val_loss: 0.0058 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 73/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0041 - my_f1_score: 0.8594 - accuracy: 0.9990 - precision_1: 0.9802 - recall_1: 0.9688 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 74/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0046 - my_f1_score: 0.9272 - accuracy: 0.9990 - precision_1: 0.9765 - recall_1: 0.9727 - val_loss: 0.0056 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 75/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0042 - my_f1_score: 0.8842 - accuracy: 0.9991 - precision_1: 0.9729 - recall_1: 0.9805 - val_loss: 0.0058 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 76/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0041 - my_f1_score: 0.8645 - accuracy: 0.9989 - precision_1: 0.9763 - recall_1: 0.9648 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 77/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0056 - my_f1_score: 0.8912 - accuracy: 0.9988 - precision_1: 0.9724 - recall_1: 0.9648 - val_loss: 0.0061 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 78/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0057 - my_f1_score: 0.8744 - accuracy: 0.9987 - precision_1: 0.9614 - recall_1: 0.9727 - val_loss: 0.0056 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 79/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0042 - my_f1_score: 0.9150 - accuracy: 0.9989 - precision_1: 0.9653 - recall_1: 0.9766 - val_loss: 0.0054 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 80/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0050 - my_f1_score: 0.8242 - accuracy: 0.9982 - precision_1: 0.9605 - recall_1: 0.9492 - val_loss: 0.0065 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 81/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0043 - my_f1_score: 0.8533 - accuracy: 0.9989 - precision_1: 0.9725 - recall_1: 0.9688 - val_loss: 0.0065 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 82/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0046 - my_f1_score: 0.8637 - accuracy: 0.9985 - precision_1: 0.9721 - recall_1: 0.9531 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 83/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0039 - my_f1_score: 0.8877 - accuracy: 0.9986 - precision_1: 0.9760 - recall_1: 0.9531 - val_loss: 0.0053 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 84/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0038 - my_f1_score: 0.9329 - accuracy: 0.9992 - precision_1: 0.9804 - recall_1: 0.9766 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 85/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0044 - my_f1_score: 0.9012 - accuracy: 0.9990 - precision_1: 0.9691 - recall_1: 0.9805 - val_loss: 0.0061 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 86/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0043 - my_f1_score: 0.8803 - accuracy: 0.9990 - precision_1: 0.9691 - recall_1: 0.9805 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 87/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0053 - my_f1_score: 0.8655 - accuracy: 0.9988 - precision_1: 0.9651 - recall_1: 0.9727 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0049 - my_f1_score: 0.9160 - accuracy: 0.9984 - precision_1: 0.9644 - recall_1: 0.9531 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 89/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0045 - my_f1_score: 0.8721 - accuracy: 0.9986 - precision_1: 0.9648 - recall_1: 0.9648 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 90/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0044 - my_f1_score: 0.8619 - accuracy: 0.9985 - precision_1: 0.9721 - recall_1: 0.9531 - val_loss: 0.0064 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 91/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0042 - my_f1_score: 0.9273 - accuracy: 0.9989 - precision_1: 0.9689 - recall_1: 0.9727 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 92/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0049 - my_f1_score: 0.8836 - accuracy: 0.9985 - precision_1: 0.9720 - recall_1: 0.9492 - val_loss: 0.0058 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 93/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0054 - my_f1_score: 0.8836 - accuracy: 0.9985 - precision_1: 0.9611 - recall_1: 0.9648 - val_loss: 0.0061 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 94/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0045 - my_f1_score: 0.8948 - accuracy: 0.9987 - precision_1: 0.9723 - recall_1: 0.9609 - val_loss: 0.0061 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 95/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0040 - my_f1_score: 0.8916 - accuracy: 0.9989 - precision_1: 0.9690 - recall_1: 0.9766 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 96/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0046 - my_f1_score: 0.8982 - accuracy: 0.9985 - precision_1: 0.9684 - recall_1: 0.9570 - val_loss: 0.0062 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 97/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0037 - my_f1_score: 0.8880 - accuracy: 0.9990 - precision_1: 0.9728 - recall_1: 0.9766 - val_loss: 0.0066 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 98/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0044 - my_f1_score: 0.9394 - accuracy: 0.9986 - precision_1: 0.9722 - recall_1: 0.9570 - val_loss: 0.0061 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 99/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0041 - my_f1_score: 0.9061 - accuracy: 0.9991 - precision_1: 0.9766 - recall_1: 0.9766 - val_loss: 0.0062 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 100/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0040 - my_f1_score: 0.9150 - accuracy: 0.9993 - precision_1: 0.9805 - recall_1: 0.9844 - val_loss: 0.0062 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 101/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0035 - my_f1_score: 0.8925 - accuracy: 0.9991 - precision_1: 0.9880 - recall_1: 0.9648 - val_loss: 0.0073 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 102/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0054 - my_f1_score: 0.8686 - accuracy: 0.9984 - precision_1: 0.9681 - recall_1: 0.9492 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 103/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0048 - my_f1_score: 0.8491 - accuracy: 0.9989 - precision_1: 0.9763 - recall_1: 0.9648 - val_loss: 0.0063 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 104/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0058 - my_f1_score: 0.8656 - accuracy: 0.9988 - precision_1: 0.9545 - recall_1: 0.9844 - val_loss: 0.0058 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 105/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0064 - my_f1_score: 0.8661 - accuracy: 0.9985 - precision_1: 0.9646 - recall_1: 0.9570 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 106/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0040 - my_f1_score: 0.9000 - accuracy: 0.9989 - precision_1: 0.9727 - recall_1: 0.9727 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 107/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0032 - my_f1_score: 0.8941 - accuracy: 0.9993 - precision_1: 0.9843 - recall_1: 0.9805 - val_loss: 0.0061 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 108/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0048 - my_f1_score: 0.9045 - accuracy: 0.9991 - precision_1: 0.9692 - recall_1: 0.9844 - val_loss: 0.0055 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 109/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0040 - my_f1_score: 0.9170 - accuracy: 0.9988 - precision_1: 0.9800 - recall_1: 0.9570 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 110/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0047 - my_f1_score: 0.8920 - accuracy: 0.9987 - precision_1: 0.9614 - recall_1: 0.9727 - val_loss: 0.0055 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 111/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0055 - my_f1_score: 0.8841 - accuracy: 0.9985 - precision_1: 0.9647 - recall_1: 0.9609 - val_loss: 0.0048 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 112/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0050 - my_f1_score: 0.8494 - accuracy: 0.9990 - precision_1: 0.9802 - recall_1: 0.9688 - val_loss: 0.0051 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 113/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0049 - my_f1_score: 0.8736 - accuracy: 0.9989 - precision_1: 0.9654 - recall_1: 0.9805 - val_loss: 0.0054 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 114/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0056 - my_f1_score: 0.9065 - accuracy: 0.9984 - precision_1: 0.9608 - recall_1: 0.9570 - val_loss: 0.0053 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 115/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0057 - my_f1_score: 0.8881 - accuracy: 0.9982 - precision_1: 0.9641 - recall_1: 0.9453 - val_loss: 0.0048 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 116/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0051 - my_f1_score: 0.9082 - accuracy: 0.9986 - precision_1: 0.9648 - recall_1: 0.9648 - val_loss: 0.0049 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0047 - my_f1_score: 0.9085 - accuracy: 0.9987 - precision_1: 0.9686 - recall_1: 0.9648 - val_loss: 0.0051 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 118/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0058 - my_f1_score: 0.8645 - accuracy: 0.9984 - precision_1: 0.9608 - recall_1: 0.9570 - val_loss: 0.0047 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 119/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0053 - my_f1_score: 0.8668 - accuracy: 0.9988 - precision_1: 0.9651 - recall_1: 0.9727 - val_loss: 0.0049 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 120/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0052 - my_f1_score: 0.8672 - accuracy: 0.9984 - precision_1: 0.9681 - recall_1: 0.9492 - val_loss: 0.0048 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 121/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0056 - my_f1_score: 0.8771 - accuracy: 0.9985 - precision_1: 0.9646 - recall_1: 0.9570 - val_loss: 0.0044 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 122/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0053 - my_f1_score: 0.8643 - accuracy: 0.9983 - precision_1: 0.9606 - recall_1: 0.9531 - val_loss: 0.0047 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 123/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0047 - my_f1_score: 0.9123 - accuracy: 0.9985 - precision_1: 0.9759 - recall_1: 0.9492 - val_loss: 0.0050 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 124/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0048 - my_f1_score: 0.8834 - accuracy: 0.9989 - precision_1: 0.9725 - recall_1: 0.9688 - val_loss: 0.0046 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 125/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0047 - my_f1_score: 0.8698 - accuracy: 0.9987 - precision_1: 0.9686 - recall_1: 0.9648 - val_loss: 0.0050 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 126/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0057 - my_f1_score: 0.8850 - accuracy: 0.9981 - precision_1: 0.9494 - recall_1: 0.9531 - val_loss: 0.0050 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 127/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0051 - my_f1_score: 0.8538 - accuracy: 0.9987 - precision_1: 0.9723 - recall_1: 0.9609 - val_loss: 0.0045 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 128/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0038 - my_f1_score: 0.9298 - accuracy: 0.9990 - precision_1: 0.9691 - recall_1: 0.9805 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 129/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0064 - my_f1_score: 0.8990 - accuracy: 0.9986 - precision_1: 0.9508 - recall_1: 0.9805 - val_loss: 0.0052 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 130/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0043 - my_f1_score: 0.8672 - accuracy: 0.9986 - precision_1: 0.9760 - recall_1: 0.9531 - val_loss: 0.0052 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 131/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0051 - my_f1_score: 0.8671 - accuracy: 0.9988 - precision_1: 0.9724 - recall_1: 0.9648 - val_loss: 0.0051 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 132/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0045 - my_f1_score: 0.8829 - accuracy: 0.9989 - precision_1: 0.9725 - recall_1: 0.9688 - val_loss: 0.0052 - val_my_f1_score: 0.8604 - val_accuracy: 0.9988 - val_precision_1: 0.9552 - val_recall_1: 0.9846\n",
      "Epoch 133/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0047 - my_f1_score: 0.9022 - accuracy: 0.9989 - precision_1: 0.9764 - recall_1: 0.9688 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 134/200\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0049 - my_f1_score: 0.8730 - accuracy: 0.9984 - precision_1: 0.9681 - recall_1: 0.9492 - val_loss: 0.0066 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 135/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0047 - my_f1_score: 0.8893 - accuracy: 0.9988 - precision_1: 0.9762 - recall_1: 0.9609 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 136/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0052 - my_f1_score: 0.8493 - accuracy: 0.9982 - precision_1: 0.9603 - recall_1: 0.9453 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 137/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0042 - my_f1_score: 0.8950 - accuracy: 0.9989 - precision_1: 0.9725 - recall_1: 0.9688 - val_loss: 0.0058 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 138/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0032 - my_f1_score: 0.9004 - accuracy: 0.9993 - precision_1: 0.9805 - recall_1: 0.9844 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 139/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0044 - my_f1_score: 0.8867 - accuracy: 0.9986 - precision_1: 0.9722 - recall_1: 0.9570 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 140/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0052 - my_f1_score: 0.8664 - accuracy: 0.9985 - precision_1: 0.9758 - recall_1: 0.9453 - val_loss: 0.0058 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 141/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0037 - my_f1_score: 0.9199 - accuracy: 0.9993 - precision_1: 0.9768 - recall_1: 0.9883 - val_loss: 0.0056 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 142/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0043 - my_f1_score: 0.8911 - accuracy: 0.9989 - precision_1: 0.9689 - recall_1: 0.9727 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 143/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0046 - my_f1_score: 0.8759 - accuracy: 0.9988 - precision_1: 0.9615 - recall_1: 0.9766 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 144/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0036 - my_f1_score: 0.8937 - accuracy: 0.9992 - precision_1: 0.9842 - recall_1: 0.9727 - val_loss: 0.0063 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 145/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0043 - my_f1_score: 0.8528 - accuracy: 0.9982 - precision_1: 0.9679 - recall_1: 0.9414 - val_loss: 0.0061 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0041 - my_f1_score: 0.8903 - accuracy: 0.9995 - precision_1: 0.9770 - recall_1: 0.9961 - val_loss: 0.0062 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 147/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0034 - my_f1_score: 0.9090 - accuracy: 0.9992 - precision_1: 0.9731 - recall_1: 0.9883 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 148/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0038 - my_f1_score: 0.8943 - accuracy: 0.9991 - precision_1: 0.9729 - recall_1: 0.9805 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 149/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0038 - my_f1_score: 0.9195 - accuracy: 0.9990 - precision_1: 0.9728 - recall_1: 0.9766 - val_loss: 0.0064 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 150/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0058 - my_f1_score: 0.8670 - accuracy: 0.9985 - precision_1: 0.9609 - recall_1: 0.9609 - val_loss: 0.0065 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 151/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0049 - my_f1_score: 0.8743 - accuracy: 0.9983 - precision_1: 0.9718 - recall_1: 0.9414 - val_loss: 0.0062 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 152/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0042 - my_f1_score: 0.9062 - accuracy: 0.9992 - precision_1: 0.9767 - recall_1: 0.9805 - val_loss: 0.0074 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 153/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0042 - my_f1_score: 0.8780 - accuracy: 0.9990 - precision_1: 0.9728 - recall_1: 0.9766 - val_loss: 0.0069 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 154/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0039 - my_f1_score: 0.9075 - accuracy: 0.9988 - precision_1: 0.9762 - recall_1: 0.9609 - val_loss: 0.0068 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 155/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0044 - my_f1_score: 0.8914 - accuracy: 0.9988 - precision_1: 0.9762 - recall_1: 0.9609 - val_loss: 0.0048 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 156/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0040 - my_f1_score: 0.8667 - accuracy: 0.9990 - precision_1: 0.9802 - recall_1: 0.9688 - val_loss: 0.0055 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 157/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0051 - my_f1_score: 0.8791 - accuracy: 0.9987 - precision_1: 0.9650 - recall_1: 0.9688 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 158/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0040 - my_f1_score: 0.9042 - accuracy: 0.9985 - precision_1: 0.9684 - recall_1: 0.9570 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 159/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0048 - my_f1_score: 0.9035 - accuracy: 0.9990 - precision_1: 0.9691 - recall_1: 0.9805 - val_loss: 0.0061 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 160/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0044 - my_f1_score: 0.8805 - accuracy: 0.9987 - precision_1: 0.9650 - recall_1: 0.9688 - val_loss: 0.0067 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 161/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0042 - my_f1_score: 0.8418 - accuracy: 0.9988 - precision_1: 0.9688 - recall_1: 0.9688 - val_loss: 0.0068 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 162/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0047 - my_f1_score: 0.9243 - accuracy: 0.9989 - precision_1: 0.9764 - recall_1: 0.9688 - val_loss: 0.0058 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 163/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0053 - my_f1_score: 0.9036 - accuracy: 0.9986 - precision_1: 0.9648 - recall_1: 0.9648 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 164/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0045 - my_f1_score: 0.8830 - accuracy: 0.9988 - precision_1: 0.9724 - recall_1: 0.9648 - val_loss: 0.0069 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 165/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0054 - my_f1_score: 0.9088 - accuracy: 0.9987 - precision_1: 0.9614 - recall_1: 0.9727 - val_loss: 0.0067 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 166/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0037 - my_f1_score: 0.8734 - accuracy: 0.9987 - precision_1: 0.9761 - recall_1: 0.9570 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 167/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0046 - my_f1_score: 0.8986 - accuracy: 0.9989 - precision_1: 0.9653 - recall_1: 0.9766 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 168/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0052 - my_f1_score: 0.8733 - accuracy: 0.9982 - precision_1: 0.9603 - recall_1: 0.9453 - val_loss: 0.0064 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 169/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0056 - my_f1_score: 0.8120 - accuracy: 0.9982 - precision_1: 0.9677 - recall_1: 0.9375 - val_loss: 0.0058 - val_my_f1_score: 0.8527 - val_accuracy: 0.9985 - val_precision_1: 0.9412 - val_recall_1: 0.9846\n",
      "Epoch 170/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0037 - my_f1_score: 0.9084 - accuracy: 0.9992 - precision_1: 0.9805 - recall_1: 0.9805 - val_loss: 0.0058 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 171/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0059 - my_f1_score: 0.9125 - accuracy: 0.9990 - precision_1: 0.9655 - recall_1: 0.9844 - val_loss: 0.0053 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 172/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0037 - my_f1_score: 0.8928 - accuracy: 0.9989 - precision_1: 0.9801 - recall_1: 0.9609 - val_loss: 0.0050 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 173/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0042 - my_f1_score: 0.8597 - accuracy: 0.9988 - precision_1: 0.9839 - recall_1: 0.9531 - val_loss: 0.0058 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 174/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0051 - my_f1_score: 0.8538 - accuracy: 0.9989 - precision_1: 0.9690 - recall_1: 0.9766 - val_loss: 0.0055 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0059 - my_f1_score: 0.8327 - accuracy: 0.9989 - precision_1: 0.9617 - recall_1: 0.9805 - val_loss: 0.0049 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 176/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0059 - my_f1_score: 0.8794 - accuracy: 0.9982 - precision_1: 0.9605 - recall_1: 0.9492 - val_loss: 0.0051 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 177/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0046 - my_f1_score: 0.9054 - accuracy: 0.9987 - precision_1: 0.9761 - recall_1: 0.9570 - val_loss: 0.0051 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 178/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0035 - my_f1_score: 0.8981 - accuracy: 0.9992 - precision_1: 0.9842 - recall_1: 0.9727 - val_loss: 0.0055 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 179/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0041 - my_f1_score: 0.8620 - accuracy: 0.9990 - precision_1: 0.9691 - recall_1: 0.9805 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 180/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0040 - my_f1_score: 0.8866 - accuracy: 0.9985 - precision_1: 0.9684 - recall_1: 0.9570 - val_loss: 0.0055 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 181/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0046 - my_f1_score: 0.9156 - accuracy: 0.9989 - precision_1: 0.9725 - recall_1: 0.9688 - val_loss: 0.0056 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 182/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0048 - my_f1_score: 0.8808 - accuracy: 0.9985 - precision_1: 0.9798 - recall_1: 0.9453 - val_loss: 0.0057 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 183/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0038 - my_f1_score: 0.9143 - accuracy: 0.9993 - precision_1: 0.9768 - recall_1: 0.9883 - val_loss: 0.0057 - val_my_f1_score: 0.8659 - val_accuracy: 0.9991 - val_precision_1: 0.9559 - val_recall_1: 1.0000\n",
      "Epoch 184/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0046 - my_f1_score: 0.8590 - accuracy: 0.9989 - precision_1: 0.9690 - recall_1: 0.9766 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 185/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0027 - my_f1_score: 0.9421 - accuracy: 0.9995 - precision_1: 0.9807 - recall_1: 0.9922 - val_loss: 0.0062 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 186/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0046 - my_f1_score: 0.9008 - accuracy: 0.9990 - precision_1: 0.9728 - recall_1: 0.9766 - val_loss: 0.0068 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 187/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0045 - my_f1_score: 0.8813 - accuracy: 0.9989 - precision_1: 0.9690 - recall_1: 0.9766 - val_loss: 0.0064 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 188/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0035 - my_f1_score: 0.8867 - accuracy: 0.9994 - precision_1: 0.9769 - recall_1: 0.9922 - val_loss: 0.0062 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 189/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0041 - my_f1_score: 0.9298 - accuracy: 0.9991 - precision_1: 0.9692 - recall_1: 0.9844 - val_loss: 0.0067 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 190/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0042 - my_f1_score: 0.8914 - accuracy: 0.9990 - precision_1: 0.9655 - recall_1: 0.9844 - val_loss: 0.0067 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 191/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0053 - my_f1_score: 0.9078 - accuracy: 0.9985 - precision_1: 0.9721 - recall_1: 0.9531 - val_loss: 0.0073 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 192/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0058 - my_f1_score: 0.8821 - accuracy: 0.9982 - precision_1: 0.9531 - recall_1: 0.9531 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 193/200\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0043 - my_f1_score: 0.8573 - accuracy: 0.9986 - precision_1: 0.9722 - recall_1: 0.9570 - val_loss: 0.0054 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 194/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0040 - my_f1_score: 0.8563 - accuracy: 0.9992 - precision_1: 0.9805 - recall_1: 0.9805 - val_loss: 0.0053 - val_my_f1_score: 0.8604 - val_accuracy: 0.9988 - val_precision_1: 0.9552 - val_recall_1: 0.9846\n",
      "Epoch 195/200\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0045 - my_f1_score: 0.8858 - accuracy: 0.9984 - precision_1: 0.9681 - recall_1: 0.9492 - val_loss: 0.0062 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 196/200\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0040 - my_f1_score: 0.8960 - accuracy: 0.9988 - precision_1: 0.9724 - recall_1: 0.9648 - val_loss: 0.0061 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 197/200\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0050 - my_f1_score: 0.8486 - accuracy: 0.9992 - precision_1: 0.9730 - recall_1: 0.9844 - val_loss: 0.0059 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 198/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0036 - my_f1_score: 0.9469 - accuracy: 0.9989 - precision_1: 0.9725 - recall_1: 0.9688 - val_loss: 0.0054 - val_my_f1_score: 0.8527 - val_accuracy: 0.9985 - val_precision_1: 0.9412 - val_recall_1: 0.9846\n",
      "Epoch 199/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0045 - my_f1_score: 0.8513 - accuracy: 0.9984 - precision_1: 0.9719 - recall_1: 0.9453 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n",
      "Epoch 200/200\n",
      "102/102 [==============================] - 1s 5ms/step - loss: 0.0036 - my_f1_score: 0.8576 - accuracy: 0.9990 - precision_1: 0.9802 - recall_1: 0.9688 - val_loss: 0.0060 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_1: 0.9420 - val_recall_1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "VALIDATION_RATIO = 0.2\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 200\n",
    "\n",
    "def fit_model(model, X, y, with_es=False):\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=5,\n",
    "        # min_delta=0.00001,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    print(\"model.fit\")\n",
    "    return model.fit(\n",
    "        X, y,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=VALIDATION_RATIO,\n",
    "        verbose=VERBOSITY,\n",
    "        callbacks=[early_stopping] if with_es else []\n",
    "    )\n",
    "\n",
    "\n",
    "history = fit_model(model, X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 1s 4ms/step - loss: 0.0012 - my_f1_score: 0.4687 - accuracy: 0.9998 - precision_1: 0.9875 - recall_1: 1.0000\n",
      "0.0012493579415604472 0.4687499701976776 0.9997549653053284 0.987500011920929 1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_f1, test_accuracy, test_precision, test_recall = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(test_loss, test_f1, test_accuracy, test_precision, test_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:07:12.924733Z",
     "start_time": "2023-04-11T15:07:12.134558Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4002\n",
      "           1       0.99      1.00      0.99        79\n",
      "\n",
      "    accuracy                           1.00      4081\n",
      "   macro avg       0.99      1.00      1.00      4081\n",
      "weighted avg       1.00      1.00      1.00      4081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# evaluate the model without fine tuning\n",
    "y_pred = model.predict(X_test, verbose=VERBOSITY) > 0.5\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T12:20:05.134416Z",
     "start_time": "2023-04-11T11:55:42.287138Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12576/1518121525.py:4: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=build_model, verbose=VERBOSITY)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "340/340 - 2s - loss: 0.1127 - my_f1_score: 0.0000e+00 - accuracy: 0.9802 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.2385 - my_f1_score: 0.0067 - accuracy: 0.9248 - precision_3: 0.0263 - recall_3: 0.0829 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1520 - my_f1_score: 0.0000e+00 - accuracy: 0.9768 - precision_4: 0.0000e+00 - recall_4: 0.0000e+00 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0785 - my_f1_score: 0.0635 - accuracy: 0.9832 - precision_5: 1.0000 - recall_5: 0.1368 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0868 - my_f1_score: 0.0069 - accuracy: 0.9802 - precision_6: 0.1875 - recall_6: 0.0146 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 1s - loss: 0.1070 - my_f1_score: 0.0000e+00 - accuracy: 0.9789 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00 - 1s/epoch - 4ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0766 - my_f1_score: 0.0955 - accuracy: 0.9793 - precision_8: 0.4270 - recall_8: 0.1792 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0859 - my_f1_score: 4.9362e-04 - accuracy: 0.9724 - precision_9: 0.0202 - recall_9: 0.0098 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0665 - my_f1_score: 0.1739 - accuracy: 0.9841 - precision_10: 0.7407 - recall_10: 0.3556 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1562 - my_f1_score: 0.0021 - accuracy: 0.9590 - precision_11: 0.0244 - recall_11: 0.0283 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1259 - my_f1_score: 0.0000e+00 - accuracy: 0.9805 - precision_12: 0.0000e+00 - recall_12: 0.0000e+00 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1189 - my_f1_score: 0.0295 - accuracy: 0.9724 - precision_13: 0.1495 - recall_13: 0.0711 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.1025 - my_f1_score: 0.0539 - accuracy: 0.9751 - precision_14: 0.2190 - recall_14: 0.1085 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0822 - my_f1_score: 0.0000e+00 - accuracy: 0.9809 - precision_15: 0.0000e+00 - recall_15: 0.0000e+00 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0805 - my_f1_score: 0.0319 - accuracy: 0.9807 - precision_16: 1.0000 - recall_16: 0.0667 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0563 - my_f1_score: 0.2363 - accuracy: 0.9876 - precision_17: 0.8031 - recall_17: 0.4811 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0688 - my_f1_score: 0.1764 - accuracy: 0.9805 - precision_18: 0.4793 - recall_18: 0.3951 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0677 - my_f1_score: 0.1691 - accuracy: 0.9851 - precision_19: 0.8387 - recall_19: 0.3467 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.1050 - my_f1_score: 0.0000e+00 - accuracy: 0.9801 - precision_20: 0.0000e+00 - recall_20: 0.0000e+00 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0992 - my_f1_score: 0.0000e+00 - accuracy: 0.9799 - precision_21: 0.0000e+00 - recall_21: 0.0000e+00 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1410 - my_f1_score: 0.0000e+00 - accuracy: 0.9771 - precision_22: 0.0000e+00 - recall_22: 0.0000e+00 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0842 - my_f1_score: 0.0886 - accuracy: 0.9762 - precision_23: 0.3285 - recall_23: 0.2123 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0835 - my_f1_score: 0.0528 - accuracy: 0.9824 - precision_24: 0.7333 - recall_24: 0.1073 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0652 - my_f1_score: 0.0485 - accuracy: 0.9811 - precision_25: 0.9524 - recall_25: 0.0889 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0555 - my_f1_score: 0.1809 - accuracy: 0.9878 - precision_26: 0.9341 - recall_26: 0.4009 - 2s/epoch - 7ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0519 - my_f1_score: 0.1798 - accuracy: 0.9845 - precision_27: 0.6475 - recall_27: 0.3854 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0566 - my_f1_score: 0.2132 - accuracy: 0.9863 - precision_28: 0.8115 - recall_28: 0.4400 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1573 - my_f1_score: 0.0020 - accuracy: 0.9703 - precision_29: 0.0174 - recall_29: 0.0094 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1527 - my_f1_score: 0.0024 - accuracy: 0.9707 - precision_30: 0.0403 - recall_30: 0.0244 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 1s - loss: 0.2001 - my_f1_score: 0.0010 - accuracy: 0.9436 - precision_31: 0.0076 - recall_31: 0.0133 - 1s/epoch - 4ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1255 - my_f1_score: 0.0000e+00 - accuracy: 0.9663 - precision_32: 0.0000e+00 - recall_32: 0.0000e+00 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1318 - my_f1_score: 0.0022 - accuracy: 0.9607 - precision_33: 0.0255 - recall_33: 0.0293 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1259 - my_f1_score: 7.3529e-04 - accuracy: 0.9635 - precision_34: 0.0169 - recall_34: 0.0133 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0799 - my_f1_score: 0.0340 - accuracy: 0.9756 - precision_35: 0.2088 - recall_35: 0.0896 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0874 - my_f1_score: 0.0402 - accuracy: 0.9736 - precision_36: 0.1694 - recall_36: 0.1024 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0787 - my_f1_score: 0.1088 - accuracy: 0.9791 - precision_37: 0.4904 - recall_37: 0.2267 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1698 - my_f1_score: 0.0026 - accuracy: 0.9541 - precision_38: 0.0264 - recall_38: 0.0377 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1663 - my_f1_score: 0.0013 - accuracy: 0.9554 - precision_39: 0.0172 - recall_39: 0.0244 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 3s - loss: 0.1827 - my_f1_score: 7.5758e-04 - accuracy: 0.9686 - precision_40: 0.0165 - recall_40: 0.0089 - 3s/epoch - 8ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0952 - my_f1_score: 0.0086 - accuracy: 0.9744 - precision_41: 0.0649 - recall_41: 0.0236 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0904 - my_f1_score: 0.0951 - accuracy: 0.9801 - precision_42: 0.4396 - recall_42: 0.1951 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.1114 - my_f1_score: 0.0064 - accuracy: 0.9734 - precision_43: 0.0429 - recall_43: 0.0133 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0592 - my_f1_score: 0.1889 - accuracy: 0.9870 - precision_44: 0.8034 - recall_44: 0.4434 - 2s/epoch - 6ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0691 - my_f1_score: 0.0608 - accuracy: 0.9812 - precision_45: 0.5000 - recall_45: 0.1415 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0735 - my_f1_score: 0.1055 - accuracy: 0.9747 - precision_46: 0.3239 - recall_46: 0.2044 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1246 - my_f1_score: 0.0000e+00 - accuracy: 0.9790 - precision_47: 0.0000e+00 - recall_47: 0.0000e+00 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.1362 - my_f1_score: 5.8824e-04 - accuracy: 0.9733 - precision_48: 0.0115 - recall_48: 0.0049 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.1716 - my_f1_score: 0.0041 - accuracy: 0.9547 - precision_49: 0.0411 - recall_49: 0.0533 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0845 - my_f1_score: 0.0569 - accuracy: 0.9821 - precision_50: 0.7742 - recall_50: 0.1132 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0867 - my_f1_score: 0.0000e+00 - accuracy: 0.9802 - precision_51: 0.0000e+00 - recall_51: 0.0000e+00 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0954 - my_f1_score: 2.6738e-04 - accuracy: 0.9707 - precision_52: 0.0104 - recall_52: 0.0044 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 3s - loss: 0.0674 - my_f1_score: 0.1573 - accuracy: 0.9783 - precision_53: 0.4355 - recall_53: 0.3821 - 3s/epoch - 8ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0664 - my_f1_score: 0.1747 - accuracy: 0.9796 - precision_54: 0.4479 - recall_54: 0.3561 - 2s/epoch - 7ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0688 - my_f1_score: 0.1215 - accuracy: 0.9778 - precision_55: 0.4298 - recall_55: 0.2311 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.1700 - my_f1_score: 0.0032 - accuracy: 0.9553 - precision_56: 0.0243 - recall_56: 0.0330 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 1s - loss: 0.2077 - my_f1_score: 0.0022 - accuracy: 0.9481 - precision_57: 0.0187 - recall_57: 0.0341 - 1s/epoch - 4ms/step\n",
      "170/170 [==============================] - 0s 963us/step\n",
      "340/340 - 2s - loss: 0.1841 - my_f1_score: 0.0015 - accuracy: 0.9645 - precision_58: 0.0180 - recall_58: 0.0133 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0968 - my_f1_score: 0.0015 - accuracy: 0.9800 - precision_59: 0.1250 - recall_59: 0.0047 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1207 - my_f1_score: 0.0018 - accuracy: 0.9722 - precision_60: 0.0196 - recall_60: 0.0098 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 1s - loss: 0.1121 - my_f1_score: 0.0071 - accuracy: 0.9736 - precision_61: 0.0571 - recall_61: 0.0178 - 1s/epoch - 4ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0677 - my_f1_score: 0.0911 - accuracy: 0.9825 - precision_62: 0.7037 - recall_62: 0.1792 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0858 - my_f1_score: 0.0294 - accuracy: 0.9754 - precision_63: 0.1379 - recall_63: 0.0585 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0978 - my_f1_score: 0.0430 - accuracy: 0.9660 - precision_64: 0.1164 - recall_64: 0.0978 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1785 - my_f1_score: 0.0000e+00 - accuracy: 0.9659 - precision_65: 0.0000e+00 - recall_65: 0.0000e+00 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.1260 - my_f1_score: 0.0000e+00 - accuracy: 0.9802 - precision_66: 0.0000e+00 - recall_66: 0.0000e+00 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1903 - my_f1_score: 0.0029 - accuracy: 0.9472 - precision_67: 0.0193 - recall_67: 0.0311 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0929 - my_f1_score: 0.0000e+00 - accuracy: 0.9763 - precision_68: 0.0000e+00 - recall_68: 0.0000e+00 - 2s/epoch - 7ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0795 - my_f1_score: 0.0000e+00 - accuracy: 0.9805 - precision_69: 0.0000e+00 - recall_69: 0.0000e+00 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.1068 - my_f1_score: 8.4465e-04 - accuracy: 0.9736 - precision_70: 0.0303 - recall_70: 0.0089 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0690 - my_f1_score: 0.0336 - accuracy: 0.9774 - precision_71: 0.2344 - recall_71: 0.0708 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.0680 - my_f1_score: 0.0187 - accuracy: 0.9778 - precision_72: 0.1636 - recall_72: 0.0439 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0637 - my_f1_score: 0.1279 - accuracy: 0.9817 - precision_73: 0.6512 - recall_73: 0.2489 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.2151 - my_f1_score: 0.0017 - accuracy: 0.9383 - precision_74: 0.0148 - recall_74: 0.0330 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1117 - my_f1_score: 0.0000e+00 - accuracy: 0.9809 - precision_75: 0.0000e+00 - recall_75: 0.0000e+00 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1234 - my_f1_score: 0.0000e+00 - accuracy: 0.9781 - precision_76: 0.0000e+00 - recall_76: 0.0000e+00 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0980 - my_f1_score: 0.0000e+00 - accuracy: 0.9775 - precision_77: 0.0000e+00 - recall_77: 0.0000e+00 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1665 - my_f1_score: 0.0022 - accuracy: 0.9400 - precision_78: 0.0214 - recall_78: 0.0488 - 2s/epoch - 5ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 2s - loss: 0.1020 - my_f1_score: 0.0000e+00 - accuracy: 0.9767 - precision_79: 0.0000e+00 - recall_79: 0.0000e+00 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 1ms/step\n",
      "340/340 - 3s - loss: 0.0537 - my_f1_score: 0.0396 - accuracy: 0.9819 - precision_80: 0.8261 - recall_80: 0.0896 - 3s/epoch - 8ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0651 - my_f1_score: 0.0681 - accuracy: 0.9809 - precision_81: 0.4737 - recall_81: 0.1317 - 2s/epoch - 7ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "340/340 - 2s - loss: 0.0656 - my_f1_score: 0.0175 - accuracy: 0.9774 - precision_82: 0.2308 - recall_82: 0.0400 - 2s/epoch - 6ms/step\n",
      "170/170 [==============================] - 0s 2ms/step\n",
      "510/510 - 3s - loss: 0.0392 - my_f1_score: 0.2698 - accuracy: 0.9892 - precision_83: 0.8222 - recall_83: 0.5763 - 3s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn=build_model, verbose=VERBOSITY)\n",
    "\n",
    "param_grid = {\n",
    "    'neurons_cnt': [16, 32, 64],\n",
    "    'layers_cnt': [1, 2, 3],\n",
    "    'dropout_prob' : [0.0, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "grid_search_cv = GridSearchCV(model, param_grid=param_grid, cv=3, scoring='f1', verbose=VERBOSITY)\n",
    "gs_result = grid_search_cv.fit(X_train, y_train, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:07:17.724275Z",
     "start_time": "2023-04-11T15:07:17.634632Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.97\n",
      "{'dropout_prob': 0.1, 'layers_cnt': 3, 'neurons_cnt': 64}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best F1:\", round(gs_result.best_score_, 2))\n",
    "print(gs_result.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:07:34.384601Z",
     "start_time": "2023-04-11T15:07:20.637299Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.fit\n",
      "Epoch 1/200\n",
      "102/102 [==============================] - 2s 6ms/step - loss: 0.1320 - my_f1_score: 0.0010 - accuracy: 0.9770 - precision_84: 0.0417 - recall_84: 0.0078 - val_loss: 0.0325 - val_my_f1_score: 0.0000e+00 - val_accuracy: 0.9801 - val_precision_84: 0.0000e+00 - val_recall_84: 0.0000e+00\n",
      "Epoch 2/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0215 - my_f1_score: 0.2108 - accuracy: 0.9845 - precision_84: 0.9492 - recall_84: 0.2188 - val_loss: 0.0127 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n",
      "Epoch 3/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0077 - my_f1_score: 0.8932 - accuracy: 0.9982 - precision_84: 0.9363 - recall_84: 0.9766 - val_loss: 0.0044 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n",
      "Epoch 4/200\n",
      "102/102 [==============================] - 0s 5ms/step - loss: 0.0047 - my_f1_score: 0.8939 - accuracy: 0.9988 - precision_84: 0.9444 - recall_84: 0.9961 - val_loss: 0.0045 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n",
      "Epoch 5/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0049 - my_f1_score: 0.8927 - accuracy: 0.9989 - precision_84: 0.9481 - recall_84: 1.0000 - val_loss: 0.0045 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n",
      "Epoch 6/200\n",
      "102/102 [==============================] - 1s 9ms/step - loss: 0.0042 - my_f1_score: 0.8740 - accuracy: 0.9988 - precision_84: 0.9444 - recall_84: 0.9961 - val_loss: 0.0043 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n",
      "Epoch 7/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0042 - my_f1_score: 0.9297 - accuracy: 0.9989 - precision_84: 0.9446 - recall_84: 1.0000 - val_loss: 0.0045 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n",
      "Epoch 8/200\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0043 - my_f1_score: 0.9037 - accuracy: 0.9989 - precision_84: 0.9480 - recall_84: 0.9961 - val_loss: 0.0044 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n",
      "Epoch 9/200\n",
      "102/102 [==============================] - 1s 6ms/step - loss: 0.0039 - my_f1_score: 0.8551 - accuracy: 0.9988 - precision_84: 0.9478 - recall_84: 0.9922 - val_loss: 0.0044 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n",
      "Epoch 10/200\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0042 - my_f1_score: 0.9364 - accuracy: 0.9989 - precision_84: 0.9513 - recall_84: 0.9922 - val_loss: 0.0042 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n",
      "Epoch 11/200\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.0033 - my_f1_score: 0.8902 - accuracy: 0.9992 - precision_84: 0.9588 - recall_84: 1.0000 - val_loss: 0.0048 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n",
      "Epoch 12/200\n",
      "102/102 [==============================] - 1s 7ms/step - loss: 0.0034 - my_f1_score: 0.9131 - accuracy: 0.9988 - precision_84: 0.9511 - recall_84: 0.9883 - val_loss: 0.0049 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n",
      "Epoch 13/200\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0033 - my_f1_score: 0.9011 - accuracy: 0.9991 - precision_84: 0.9621 - recall_84: 0.9922 - val_loss: 0.0046 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n",
      "Epoch 14/200\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0031 - my_f1_score: 0.8835 - accuracy: 0.9991 - precision_84: 0.9586 - recall_84: 0.9961 - val_loss: 0.0044 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n",
      "Epoch 15/200\n",
      "102/102 [==============================] - 1s 8ms/step - loss: 0.0028 - my_f1_score: 0.9334 - accuracy: 0.9994 - precision_84: 0.9697 - recall_84: 1.0000 - val_loss: 0.0046 - val_my_f1_score: 0.8582 - val_accuracy: 0.9988 - val_precision_84: 0.9420 - val_recall_84: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f16e987a740>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Now build model with best hyperparameters\n",
    "best_model = build_model(**gs_result.best_params_)\n",
    "\n",
    "fit_model(best_model, X_train, y_train, with_es=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:07:43.798413Z",
     "start_time": "2023-04-11T15:07:42.623367Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4002\n",
      "           1       0.96      1.00      0.98        79\n",
      "\n",
      "    accuracy                           1.00      4081\n",
      "   macro avg       0.98      1.00      0.99      4081\n",
      "weighted avg       1.00      1.00      1.00      4081\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test, verbose=VERBOSITY) > 0.5\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:07:46.598406Z",
     "start_time": "2023-04-11T15:07:46.523319Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['browser', 'os', 'locale', 'location', 'time', 'date'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === VERIFY ===\n",
    "\n",
    "X_verify = preprocess(\"task_1_verify.csv\", with_y=False)\n",
    "X_verify = onehot_encode(X_verify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:07:50.026732Z",
     "start_time": "2023-04-11T15:07:49.979249Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "missing_cols = list(\n",
    "    set(X_df_columns) - set(X_verify.columns)\n",
    ")\n",
    "\n",
    "# Assign missing columns to zero\n",
    "X_verify.loc[:, missing_cols] = 0\n",
    "\n",
    "# Re-sort by initial test data columns\n",
    "X_verify = X_verify[X_df_columns]\n",
    "\n",
    "X_verify = np.array(X_verify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T15:07:53.886657Z",
     "start_time": "2023-04-11T15:07:53.546486Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "0: 0\n",
      "1: 0\n",
      "2: 0\n",
      "3: 0\n",
      "4: 0\n",
      "5: 0\n",
      "6: 0\n",
      "7: 0\n",
      "8: 0\n",
      "9: 0\n",
      "10: 0\n",
      "11: 0\n",
      "12: 0\n",
      "13: 0\n",
      "14: 0\n",
      "15: 0\n",
      "16: 0\n",
      "17: 0\n",
      "18: 0\n",
      "19: 0\n",
      "20: 0\n",
      "21: 0\n",
      "22: 0\n",
      "23: 0\n",
      "24: 0\n",
      "25: 0\n",
      "26: 0\n",
      "27: 0\n",
      "28: 0\n",
      "29: 0\n",
      "30: 0\n",
      "31: 1\n",
      "32: 1\n",
      "33: 1\n",
      "34: 1\n",
      "35: 1\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_verify, verbose=VERBOSITY) > 0.5\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    print(f\"{i}: {int(y_pred[i][0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1. Did you find any usefull insights from your data analysis?\n",
    "    - *\"sites\" column seems difficult to handle and also very unique, so I've dropped it out*\n",
    "2. What preprocessing techniques did you use? Why?\n",
    "    - *I used `OneHotEncoder` to encode categorical columns*\n",
    "    - *I used `MinMaxScaler` to scale \"date\" and \"time\" columns\n",
    "3. Describe the fine-tuning process and how you reached your model architecture.\n",
    "    - I used `GridSearchCV` to search for best\n",
    "        - count of neurons in layers,\n",
    "        - count of hidden layers,\n",
    "        - and dropout probability\n",
    "      - 'num_layers': number of hidden layers,\n",
    "      - 'dropout' : randomly setting activation of neurons to zero\n",
    "4. Which metric did you try to optemize for this task? Why?\n",
    "    - I used `F1 score` because our dataset is unbalanced, in combination with\n",
    "        - accuracy\n",
    "        - precision\n",
    "        - recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Fingerprint Recognition (50 points)\n",
    "Fingerprint recognition is a highly accurate and reliable biometric technology that is used for identification and authentication purposes. By analyzing the unique patterns and ridges on an individual's fingerprint, it is possible to verify their identity with a high degree of confidence. This technology is widely used in law enforcement, border control, and access control systems, as well as in mobile devices and payment systems, to ensure secure and reliable identification and authentication.\n",
    "\n",
    "In this task you will be doing a simplified version of Fingerprint ID, which is just identifying which finger is used in the image\n",
    "\n",
    "## What you need to do\n",
    "\n",
    "For this task, you will be doing image classification:\n",
    "- Build a CNN model for image classification.\n",
    "- Estimate the speed of inference of your model\n",
    "\n",
    "For the given data, you need to do proper data preprocessing, augmentation, and data loaders.\n",
    "\n",
    "Then fine-tune your model architecture to achieve the highest accuracy.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Select and implement suitable data preprocessing techniques. 10%\n",
    "- Use literature (any paper on the use of CNN for fingerprinting and cite it) to choose an architecture. 10%\n",
    "- Apply CNNs to solve an image classification problem (basic training, validation, testing -- without fine tuning). 40%\n",
    "- Fine-tune your model to improve performance. 20%\n",
    "- Use of data augmentation to improve models performance. 20%\n",
    "- Explore beyond data augmentation find techniques to improve models performance and use them. 15%(bonus)\n",
    "\n",
    "\n",
    "### Data\n",
    "[Download link](https://drive.google.com/file/d/1iMIdYKSmCjVL5p-yzy-oInLMtTVt-1_j/view?usp=share_link)\n",
    "\n",
    "You will be working with the data in `task_2.zip` for identifying. The name of each image consists of 2 parts like\n",
    "`idx_label.BMB`\n",
    "\n",
    "Where the idx is the index of the image and the label is the target class.\n",
    "\n",
    "Each label corresponds to a finger:\n",
    "```\n",
    "0-> left_thumb\n",
    "1-> left_index\n",
    "2-> left_middle\n",
    "3-> left_ring\n",
    "4-> left_little\n",
    "5-> right_thumb\n",
    "6-> right_index\n",
    "7-> right_middle\n",
    "8-> right_ring\n",
    "9-> right_little\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-15T23:11:47.651996Z",
     "start_time": "2023-04-15T23:11:30.871237Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 09:58:35.791068: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-16 09:58:36.027693: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-16 09:58:36.030849: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-16 09:58:37.455440: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pprint\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "RANDOM_STATE = 123\n",
    "VALIDATION_RATIO = 0.2\n",
    "VERBOSITY = 1\n",
    "\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "\n",
    "def load_data(dirpath: str):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(dirpath):\n",
    "        index, label = map(int, filename.removesuffix(\".bmp\").split(\"_\"))\n",
    "\n",
    "        img = cv2.imread(os.path.join(dirpath, filename))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        top_border = int(0.05 * img.shape[0])  # 5% of height\n",
    "        bottom_border = int(0.05 * img.shape[0])\n",
    "        left_border = int(0.05 * img.shape[1])  # 5% of width\n",
    "        right_border = int(0.05 * img.shape[1])\n",
    "\n",
    "        img = img[\n",
    "              top_border:img.shape[0] - bottom_border,\n",
    "              left_border:img.shape[1] - right_border\n",
    "        ]\n",
    "\n",
    "        img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = img.astype('float32') / 255.0\n",
    "\n",
    "        data.append(img)\n",
    "        labels.append(label)\n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    return data, labels\n",
    "\n",
    "data_train, labels_train = load_data(\"assets/task2/train\")\n",
    "X_test, y_test = load_data(\"assets/task2/test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-15T23:11:48.430461Z",
     "start_time": "2023-04-15T23:11:47.657955Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def encode_labels(y: np.array):\n",
    "    y2 = y.reshape(-1, 1)\n",
    "\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(y2)\n",
    "\n",
    "    y_encoded = encoder.transform(y2).toarray()\n",
    "    return y_encoded\n",
    "\n",
    "labels_encoded = encode_labels(labels_train)\n",
    "\n",
    "data_train = data_train.reshape(-1, IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "X_test = X_test.reshape(-1, IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    data_train,\n",
    "    labels_encoded,\n",
    "    test_size=VALIDATION_RATIO,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-15T23:11:48.749866Z",
     "start_time": "2023-04-15T23:11:48.433147Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "\n",
    "def build_model(filters=32, neurons=64, dropout=0.1):\n",
    "    kernel_size = (3, 3)\n",
    "    model = Sequential()\n",
    "\n",
    "    filters_cnt_list = [\n",
    "        filters,\n",
    "        int(filters * 0.75),\n",
    "        filters // 2\n",
    "    ]\n",
    "    padding = \"same\"\n",
    "\n",
    "    model.add(Conv2D(\n",
    "        filters=filters_cnt_list[0],\n",
    "        kernel_size=kernel_size,\n",
    "        strides=1,\n",
    "        padding=padding,\n",
    "        activation='relu',\n",
    "        input_shape=(IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "    ))\n",
    "    model.add(MaxPooling2D(\n",
    "        pool_size=(2,2),\n",
    "        strides=2,\n",
    "        padding=padding\n",
    "    ))\n",
    "\n",
    "    model.add(Conv2D(\n",
    "        filters=filters_cnt_list[1],\n",
    "        kernel_size=kernel_size,\n",
    "        strides=1,\n",
    "        padding=padding,\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(MaxPooling2D(\n",
    "        pool_size=(2,2),\n",
    "        strides=2,\n",
    "        padding=padding\n",
    "    ))\n",
    "\n",
    "    model.add(Conv2D(\n",
    "        filters=filters_cnt_list[2],\n",
    "        kernel_size=kernel_size,\n",
    "        strides=1,\n",
    "        padding=padding,\n",
    "        activation='relu'\n",
    "    ))\n",
    "\n",
    "    model.add(MaxPooling2D(\n",
    "        pool_size=(2,2),\n",
    "        strides=2,\n",
    "        padding=padding\n",
    "    ))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(\n",
    "        units=neurons,\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(\n",
    "        units=10,\n",
    "        activation='softmax'\n",
    "    ))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T00:16:43.377132Z",
     "start_time": "2023-04-15T23:11:48.725548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 23:11:48.831069: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-15 23:11:50.933663: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 134217728 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/121 [..............................] - ETA: 5:21 - loss: 2.3202 - accuracy: 0.0781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 23:11:51.402002: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 134217728 exceeds 10% of free system memory.\n",
      "2023-04-15 23:11:51.558572: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 134217728 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/121 [..............................] - ETA: 1:08 - loss: 2.3218 - accuracy: 0.1016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-15 23:11:51.989266: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 134217728 exceeds 10% of free system memory.\n",
      "2023-04-15 23:11:52.131191: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 134217728 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 67s 540ms/step - loss: 1.9723 - accuracy: 0.2731 - val_loss: 1.6144 - val_accuracy: 0.4288\n",
      "Epoch 2/100\n",
      "121/121 [==============================] - 63s 525ms/step - loss: 1.5238 - accuracy: 0.4492 - val_loss: 1.3631 - val_accuracy: 0.5107\n",
      "Epoch 3/100\n",
      "121/121 [==============================] - 63s 525ms/step - loss: 1.3456 - accuracy: 0.5119 - val_loss: 1.2758 - val_accuracy: 0.5444\n",
      "Epoch 4/100\n",
      "121/121 [==============================] - 77s 638ms/step - loss: 1.2337 - accuracy: 0.5504 - val_loss: 1.2688 - val_accuracy: 0.5514\n",
      "Epoch 5/100\n",
      "121/121 [==============================] - 78s 644ms/step - loss: 1.1495 - accuracy: 0.5860 - val_loss: 1.2253 - val_accuracy: 0.5658\n",
      "Epoch 6/100\n",
      "121/121 [==============================] - 83s 687ms/step - loss: 1.1062 - accuracy: 0.6040 - val_loss: 1.0704 - val_accuracy: 0.6199\n",
      "Epoch 7/100\n",
      "121/121 [==============================] - 81s 671ms/step - loss: 1.0453 - accuracy: 0.6182 - val_loss: 1.0336 - val_accuracy: 0.6243\n",
      "Epoch 8/100\n",
      "121/121 [==============================] - 80s 660ms/step - loss: 0.9962 - accuracy: 0.6360 - val_loss: 1.0059 - val_accuracy: 0.6552\n",
      "Epoch 9/100\n",
      "121/121 [==============================] - 79s 650ms/step - loss: 0.9788 - accuracy: 0.6445 - val_loss: 0.9511 - val_accuracy: 0.6631\n",
      "Epoch 10/100\n",
      "121/121 [==============================] - 80s 665ms/step - loss: 0.9233 - accuracy: 0.6650 - val_loss: 0.9297 - val_accuracy: 0.6716\n",
      "Epoch 11/100\n",
      "121/121 [==============================] - 83s 685ms/step - loss: 0.8914 - accuracy: 0.6721 - val_loss: 0.9361 - val_accuracy: 0.6665\n",
      "Epoch 12/100\n",
      "121/121 [==============================] - 78s 649ms/step - loss: 0.8976 - accuracy: 0.6752 - val_loss: 0.8660 - val_accuracy: 0.7025\n",
      "Epoch 13/100\n",
      "121/121 [==============================] - 81s 670ms/step - loss: 0.8154 - accuracy: 0.7040 - val_loss: 0.8300 - val_accuracy: 0.7038\n",
      "Epoch 14/100\n",
      "121/121 [==============================] - 79s 652ms/step - loss: 0.7925 - accuracy: 0.7119 - val_loss: 0.8314 - val_accuracy: 0.7098\n",
      "Epoch 15/100\n",
      "121/121 [==============================] - 79s 654ms/step - loss: 0.7480 - accuracy: 0.7270 - val_loss: 0.7880 - val_accuracy: 0.7242\n",
      "Epoch 16/100\n",
      "121/121 [==============================] - 79s 659ms/step - loss: 0.7207 - accuracy: 0.7397 - val_loss: 0.7976 - val_accuracy: 0.7237\n",
      "Epoch 17/100\n",
      "121/121 [==============================] - 81s 672ms/step - loss: 0.7104 - accuracy: 0.7319 - val_loss: 0.7816 - val_accuracy: 0.7242\n",
      "Epoch 18/100\n",
      "121/121 [==============================] - 79s 652ms/step - loss: 0.6608 - accuracy: 0.7621 - val_loss: 0.8543 - val_accuracy: 0.6997\n",
      "Epoch 19/100\n",
      "121/121 [==============================] - 79s 655ms/step - loss: 0.6472 - accuracy: 0.7674 - val_loss: 0.7404 - val_accuracy: 0.7420\n",
      "Epoch 20/100\n",
      "121/121 [==============================] - 86s 711ms/step - loss: 0.6247 - accuracy: 0.7716 - val_loss: 0.7144 - val_accuracy: 0.7450\n",
      "Epoch 21/100\n",
      "121/121 [==============================] - 85s 700ms/step - loss: 0.5922 - accuracy: 0.7817 - val_loss: 0.7391 - val_accuracy: 0.7399\n",
      "Epoch 22/100\n",
      "121/121 [==============================] - 81s 669ms/step - loss: 0.5518 - accuracy: 0.8009 - val_loss: 0.7187 - val_accuracy: 0.7541\n",
      "Epoch 23/100\n",
      "121/121 [==============================] - 82s 677ms/step - loss: 0.5441 - accuracy: 0.8069 - val_loss: 0.6218 - val_accuracy: 0.7844\n",
      "Epoch 24/100\n",
      "121/121 [==============================] - 82s 677ms/step - loss: 0.5009 - accuracy: 0.8224 - val_loss: 0.6154 - val_accuracy: 0.7919\n",
      "Epoch 25/100\n",
      "121/121 [==============================] - 84s 694ms/step - loss: 0.4677 - accuracy: 0.8350 - val_loss: 0.6145 - val_accuracy: 0.7868\n",
      "Epoch 26/100\n",
      "121/121 [==============================] - 83s 687ms/step - loss: 0.4744 - accuracy: 0.8346 - val_loss: 0.6548 - val_accuracy: 0.7677\n",
      "Epoch 27/100\n",
      "121/121 [==============================] - 83s 682ms/step - loss: 0.4474 - accuracy: 0.8418 - val_loss: 0.6086 - val_accuracy: 0.7955\n",
      "Epoch 28/100\n",
      "121/121 [==============================] - 82s 676ms/step - loss: 0.4228 - accuracy: 0.8463 - val_loss: 0.5522 - val_accuracy: 0.8038\n",
      "Epoch 29/100\n",
      "121/121 [==============================] - 81s 669ms/step - loss: 0.3992 - accuracy: 0.8604 - val_loss: 0.5541 - val_accuracy: 0.8190\n",
      "Epoch 30/100\n",
      "121/121 [==============================] - 85s 707ms/step - loss: 0.3842 - accuracy: 0.8652 - val_loss: 0.5465 - val_accuracy: 0.8213\n",
      "Epoch 31/100\n",
      "121/121 [==============================] - 81s 672ms/step - loss: 0.3564 - accuracy: 0.8729 - val_loss: 0.4935 - val_accuracy: 0.8360\n",
      "Epoch 32/100\n",
      "121/121 [==============================] - 85s 703ms/step - loss: 0.3286 - accuracy: 0.8799 - val_loss: 0.4748 - val_accuracy: 0.8473\n",
      "Epoch 33/100\n",
      "121/121 [==============================] - 79s 657ms/step - loss: 0.3174 - accuracy: 0.8837 - val_loss: 0.4846 - val_accuracy: 0.8434\n",
      "Epoch 34/100\n",
      "121/121 [==============================] - 84s 698ms/step - loss: 0.3128 - accuracy: 0.8940 - val_loss: 0.5047 - val_accuracy: 0.8362\n",
      "Epoch 35/100\n",
      "121/121 [==============================] - 84s 694ms/step - loss: 0.3070 - accuracy: 0.8905 - val_loss: 0.4603 - val_accuracy: 0.8527\n",
      "Epoch 36/100\n",
      "121/121 [==============================] - 82s 676ms/step - loss: 0.2906 - accuracy: 0.8983 - val_loss: 0.4397 - val_accuracy: 0.8578\n",
      "Epoch 37/100\n",
      "121/121 [==============================] - 83s 688ms/step - loss: 0.2513 - accuracy: 0.9116 - val_loss: 0.4602 - val_accuracy: 0.8548\n",
      "Epoch 38/100\n",
      "121/121 [==============================] - 84s 698ms/step - loss: 0.2589 - accuracy: 0.9066 - val_loss: 0.4411 - val_accuracy: 0.8666\n",
      "Epoch 39/100\n",
      "121/121 [==============================] - 83s 684ms/step - loss: 0.2748 - accuracy: 0.8998 - val_loss: 0.4146 - val_accuracy: 0.8671\n",
      "Epoch 40/100\n",
      "121/121 [==============================] - 84s 695ms/step - loss: 0.2203 - accuracy: 0.9223 - val_loss: 0.4152 - val_accuracy: 0.8728\n",
      "Epoch 41/100\n",
      "121/121 [==============================] - 83s 684ms/step - loss: 0.2172 - accuracy: 0.9225 - val_loss: 0.4342 - val_accuracy: 0.8702\n",
      "Epoch 42/100\n",
      "121/121 [==============================] - 85s 705ms/step - loss: 0.2348 - accuracy: 0.9167 - val_loss: 0.4183 - val_accuracy: 0.8792\n",
      "Epoch 43/100\n",
      "121/121 [==============================] - 82s 682ms/step - loss: 0.2018 - accuracy: 0.9295 - val_loss: 0.3884 - val_accuracy: 0.8913\n",
      "Epoch 44/100\n",
      "121/121 [==============================] - 85s 707ms/step - loss: 0.2157 - accuracy: 0.9260 - val_loss: 0.4643 - val_accuracy: 0.8656\n",
      "Epoch 45/100\n",
      "121/121 [==============================] - 80s 661ms/step - loss: 0.1902 - accuracy: 0.9353 - val_loss: 0.4091 - val_accuracy: 0.8815\n",
      "Epoch 46/100\n",
      "121/121 [==============================] - 83s 689ms/step - loss: 0.2048 - accuracy: 0.9299 - val_loss: 0.4115 - val_accuracy: 0.8800\n",
      "Epoch 47/100\n",
      "121/121 [==============================] - 83s 683ms/step - loss: 0.1881 - accuracy: 0.9329 - val_loss: 0.3937 - val_accuracy: 0.8882\n",
      "Epoch 48/100\n",
      "121/121 [==============================] - 84s 695ms/step - loss: 0.1810 - accuracy: 0.9369 - val_loss: 0.3892 - val_accuracy: 0.8895\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "# datagen.fit(X_train)\n",
    "\n",
    "\n",
    "def fit_model(model, datagen, X_train, y_train, X_val, y_val):\n",
    "    es = EarlyStopping(patience=10, min_delta=0.0005, restore_best_weights=True)\n",
    "    \n",
    "    return model.fit(\n",
    "        datagen.flow(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            batch_size=BATCH_SIZE\n",
    "        ),\n",
    "        steps_per_epoch=len(X_train) // (BATCH_SIZE * 2),\n",
    "        validation_steps=len(X_val) // (BATCH_SIZE * 2),\n",
    "        validation_data=(\n",
    "            X_val,\n",
    "            y_val\n",
    "        ),\n",
    "        # validation_split=VALIDATION_RATIO,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[es],\n",
    "        verbose=VERBOSITY,\n",
    "    )\n",
    "\n",
    "history = fit_model(model, datagen, X_train, y_train, X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T00:16:44.138764Z",
     "start_time": "2023-04-16T00:16:43.382179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_history_acc(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "draw_history_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T00:17:09.659336Z",
     "start_time": "2023-04-16T00:16:44.649835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 25s 55ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      1617\n",
      "           1       0.78      0.80      0.79      1415\n",
      "           2       0.77      0.78      0.78      1479\n",
      "           3       0.79      0.77      0.78      1498\n",
      "           4       0.81      0.79      0.80      1372\n",
      "           5       0.94      0.96      0.95      1467\n",
      "           6       0.86      0.85      0.86      1305\n",
      "           7       0.82      0.84      0.83      1369\n",
      "           8       0.87      0.76      0.81      1406\n",
      "           9       0.78      0.86      0.82      1344\n",
      "\n",
      "    accuracy                           0.84     14272\n",
      "   macro avg       0.84      0.83      0.83     14272\n",
      "weighted avg       0.84      0.84      0.84     14272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_test = encode_labels(y_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "evaluate_model(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-16T08:10:25.809053Z",
     "start_time": "2023-04-16T00:17:09.636946Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12576/2113864958.py:10: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 27 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 10:00:24.668727: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 763297792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 119s 326ms/step - loss: 1.9246 - accuracy: 0.2834\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 1.6610 - accuracy: 0.3948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 10:02:35.305083: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 763297792 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 124s 339ms/step - loss: 1.7335 - accuracy: 0.3683\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 1.4467 - accuracy: 0.4715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 10:04:51.124379: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 763363328 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 109s 298ms/step - loss: 1.8031 - accuracy: 0.3451\n",
      "122/122 [==============================] - 7s 53ms/step - loss: 1.3971 - accuracy: 0.4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 10:06:50.753679: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 763363328 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 115s 313ms/step - loss: 1.7215 - accuracy: 0.3785\n",
      "122/122 [==============================] - 7s 53ms/step - loss: 1.3917 - accuracy: 0.4987\n",
      "364/364 [==============================] - 107s 293ms/step - loss: 1.7043 - accuracy: 0.3745\n",
      "122/122 [==============================] - 7s 53ms/step - loss: 1.4502 - accuracy: 0.4826\n",
      "364/364 [==============================] - 109s 298ms/step - loss: 1.7635 - accuracy: 0.3452\n",
      "122/122 [==============================] - 7s 53ms/step - loss: 1.3588 - accuracy: 0.5120\n",
      "364/364 [==============================] - 114s 310ms/step - loss: 1.7672 - accuracy: 0.3484\n",
      "122/122 [==============================] - 6s 51ms/step - loss: 1.3168 - accuracy: 0.5139\n",
      "364/364 [==============================] - 107s 292ms/step - loss: 1.6458 - accuracy: 0.3983\n",
      "122/122 [==============================] - 6s 51ms/step - loss: 1.4833 - accuracy: 0.4678\n",
      "364/364 [==============================] - 108s 295ms/step - loss: 1.5537 - accuracy: 0.4403\n",
      "122/122 [==============================] - 7s 54ms/step - loss: 1.2183 - accuracy: 0.5653\n",
      "364/364 [==============================] - 104s 283ms/step - loss: 1.5883 - accuracy: 0.4246\n",
      "122/122 [==============================] - 7s 53ms/step - loss: 1.2621 - accuracy: 0.5411\n",
      "364/364 [==============================] - 114s 311ms/step - loss: 1.5651 - accuracy: 0.4295\n",
      "122/122 [==============================] - 6s 51ms/step - loss: 1.1785 - accuracy: 0.5652\n",
      "364/364 [==============================] - 115s 313ms/step - loss: 1.7164 - accuracy: 0.3749\n",
      "122/122 [==============================] - 7s 53ms/step - loss: 1.4017 - accuracy: 0.4835\n",
      "364/364 [==============================] - 178s 479ms/step - loss: 1.6385 - accuracy: 0.4030\n",
      "122/122 [==============================] - 11s 92ms/step - loss: 1.2751 - accuracy: 0.5480\n",
      "364/364 [==============================] - 187s 511ms/step - loss: 2.0375 - accuracy: 0.2494\n",
      "122/122 [==============================] - 15s 124ms/step - loss: 1.7174 - accuracy: 0.3788\n",
      "364/364 [==============================] - 188s 513ms/step - loss: 1.7186 - accuracy: 0.3766\n",
      "122/122 [==============================] - 15s 121ms/step - loss: 1.3341 - accuracy: 0.5196\n",
      "364/364 [==============================] - 191s 521ms/step - loss: 1.8021 - accuracy: 0.3404\n",
      "122/122 [==============================] - 14s 110ms/step - loss: 1.5042 - accuracy: 0.4560\n",
      "364/364 [==============================] - 183s 501ms/step - loss: 1.7159 - accuracy: 0.3728\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 1.3289 - accuracy: 0.5166\n",
      "364/364 [==============================] - 183s 499ms/step - loss: 1.7287 - accuracy: 0.3650\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 1.3417 - accuracy: 0.5264\n",
      "364/364 [==============================] - 171s 466ms/step - loss: 1.6924 - accuracy: 0.3880\n",
      "122/122 [==============================] - 13s 103ms/step - loss: 1.2767 - accuracy: 0.5438\n",
      "364/364 [==============================] - 171s 466ms/step - loss: 1.6771 - accuracy: 0.3905\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 1.3108 - accuracy: 0.5392\n",
      "364/364 [==============================] - 177s 483ms/step - loss: 1.5478 - accuracy: 0.4338\n",
      "122/122 [==============================] - 13s 103ms/step - loss: 1.3800 - accuracy: 0.4816\n",
      "364/364 [==============================] - 176s 480ms/step - loss: 1.5623 - accuracy: 0.4372\n",
      "122/122 [==============================] - 14s 116ms/step - loss: 1.2711 - accuracy: 0.5326\n",
      "364/364 [==============================] - 163s 437ms/step - loss: 1.6165 - accuracy: 0.4167\n",
      "122/122 [==============================] - 12s 97ms/step - loss: 1.2078 - accuracy: 0.5726\n",
      "364/364 [==============================] - 181s 494ms/step - loss: 1.5776 - accuracy: 0.4257\n",
      "122/122 [==============================] - 14s 110ms/step - loss: 1.2446 - accuracy: 0.5538\n",
      "364/364 [==============================] - 424s 1s/step - loss: 1.6968 - accuracy: 0.3807\n",
      "122/122 [==============================] - 35s 283ms/step - loss: 1.3620 - accuracy: 0.5040\n",
      "364/364 [==============================] - 422s 1s/step - loss: 1.7303 - accuracy: 0.3544\n",
      "122/122 [==============================] - 35s 284ms/step - loss: 1.3571 - accuracy: 0.5068\n",
      "364/364 [==============================] - 422s 1s/step - loss: 1.7121 - accuracy: 0.3763\n",
      "122/122 [==============================] - 34s 281ms/step - loss: 1.2831 - accuracy: 0.5229\n",
      "364/364 [==============================] - 422s 1s/step - loss: 1.6783 - accuracy: 0.3808\n",
      "122/122 [==============================] - 34s 279ms/step - loss: 1.3333 - accuracy: 0.5070\n",
      "364/364 [==============================] - 419s 1s/step - loss: 1.7396 - accuracy: 0.3638\n",
      "122/122 [==============================] - 34s 280ms/step - loss: 1.4501 - accuracy: 0.4849\n",
      "364/364 [==============================] - 420s 1s/step - loss: 1.7857 - accuracy: 0.3426\n",
      "122/122 [==============================] - 34s 281ms/step - loss: 1.4484 - accuracy: 0.4618\n",
      "364/364 [==============================] - 425s 1s/step - loss: 1.7313 - accuracy: 0.3723\n",
      "122/122 [==============================] - 35s 281ms/step - loss: 1.4536 - accuracy: 0.4791\n",
      "364/364 [==============================] - 431s 1s/step - loss: 1.7773 - accuracy: 0.3457\n",
      "122/122 [==============================] - 31s 254ms/step - loss: 1.3764 - accuracy: 0.5003\n",
      "364/364 [==============================] - 493s 1s/step - loss: 1.5839 - accuracy: 0.4226\n",
      "122/122 [==============================] - 39s 321ms/step - loss: 1.2648 - accuracy: 0.5514\n",
      "364/364 [==============================] - 475s 1s/step - loss: 1.6475 - accuracy: 0.4028\n",
      "122/122 [==============================] - 35s 284ms/step - loss: 1.2667 - accuracy: 0.5439\n",
      "364/364 [==============================] - 476s 1s/step - loss: 1.6600 - accuracy: 0.4000\n",
      "122/122 [==============================] - 35s 289ms/step - loss: 1.3769 - accuracy: 0.5088\n",
      "364/364 [==============================] - 434s 1s/step - loss: 1.5954 - accuracy: 0.4174\n",
      "122/122 [==============================] - 35s 284ms/step - loss: 1.2205 - accuracy: 0.5572\n",
      "364/364 [==============================] - 108s 295ms/step - loss: 1.8359 - accuracy: 0.3264\n",
      "122/122 [==============================] - 7s 55ms/step - loss: 1.4212 - accuracy: 0.4860\n",
      "364/364 [==============================] - 104s 284ms/step - loss: 2.1275 - accuracy: 0.2073\n",
      "122/122 [==============================] - 7s 57ms/step - loss: 1.9275 - accuracy: 0.2962\n",
      "364/364 [==============================] - 89s 243ms/step - loss: 1.8994 - accuracy: 0.2774\n",
      "122/122 [==============================] - 7s 53ms/step - loss: 1.4584 - accuracy: 0.4650\n",
      "364/364 [==============================] - 92s 251ms/step - loss: 1.8930 - accuracy: 0.3117\n",
      "122/122 [==============================] - 7s 58ms/step - loss: 1.5726 - accuracy: 0.4276\n",
      "364/364 [==============================] - 93s 253ms/step - loss: 1.7278 - accuracy: 0.3649\n",
      "122/122 [==============================] - 6s 46ms/step - loss: 1.3439 - accuracy: 0.5205\n",
      "364/364 [==============================] - 95s 248ms/step - loss: 1.6633 - accuracy: 0.3981\n",
      "122/122 [==============================] - 5s 43ms/step - loss: 1.2601 - accuracy: 0.5434\n",
      "364/364 [==============================] - 86s 232ms/step - loss: 1.6739 - accuracy: 0.3848\n",
      "122/122 [==============================] - 6s 46ms/step - loss: 1.2191 - accuracy: 0.5587\n",
      "364/364 [==============================] - 111s 302ms/step - loss: 1.7024 - accuracy: 0.3818\n",
      "122/122 [==============================] - 8s 61ms/step - loss: 1.2972 - accuracy: 0.5461\n",
      "364/364 [==============================] - 114s 311ms/step - loss: 1.7272 - accuracy: 0.3713\n",
      "122/122 [==============================] - 7s 60ms/step - loss: 1.3634 - accuracy: 0.5089\n",
      "364/364 [==============================] - 109s 298ms/step - loss: 1.6622 - accuracy: 0.3925\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 1.2612 - accuracy: 0.5493\n",
      "364/364 [==============================] - 114s 311ms/step - loss: 1.7002 - accuracy: 0.3725\n",
      "122/122 [==============================] - 8s 61ms/step - loss: 1.2993 - accuracy: 0.5183\n",
      "364/364 [==============================] - 110s 300ms/step - loss: 1.6657 - accuracy: 0.3908\n",
      "122/122 [==============================] - 7s 59ms/step - loss: 1.2962 - accuracy: 0.5386\n",
      "364/364 [==============================] - 170s 465ms/step - loss: 1.8039 - accuracy: 0.3345\n",
      "122/122 [==============================] - 14s 115ms/step - loss: 1.4948 - accuracy: 0.4504\n",
      "364/364 [==============================] - 171s 466ms/step - loss: 1.9488 - accuracy: 0.2829\n",
      "122/122 [==============================] - 14s 116ms/step - loss: 1.5614 - accuracy: 0.4533\n",
      "364/364 [==============================] - 174s 475ms/step - loss: 2.0287 - accuracy: 0.2635\n",
      "122/122 [==============================] - 13s 105ms/step - loss: 1.7347 - accuracy: 0.3614\n",
      "364/364 [==============================] - 157s 430ms/step - loss: 1.8756 - accuracy: 0.3008\n",
      "122/122 [==============================] - 11s 92ms/step - loss: 1.5165 - accuracy: 0.4513\n",
      "364/364 [==============================] - 186s 510ms/step - loss: 1.6696 - accuracy: 0.3867\n",
      "122/122 [==============================] - 14s 115ms/step - loss: 1.2385 - accuracy: 0.5576\n",
      "364/364 [==============================] - 188s 514ms/step - loss: 1.8067 - accuracy: 0.3350\n",
      "122/122 [==============================] - 14s 110ms/step - loss: 1.4118 - accuracy: 0.4880\n",
      "364/364 [==============================] - 184s 503ms/step - loss: 1.7209 - accuracy: 0.3663\n",
      "122/122 [==============================] - 14s 113ms/step - loss: 1.2482 - accuracy: 0.5438\n",
      "364/364 [==============================] - 186s 509ms/step - loss: 1.8450 - accuracy: 0.3198\n",
      "122/122 [==============================] - 13s 107ms/step - loss: 1.3979 - accuracy: 0.5072\n",
      "364/364 [==============================] - 185s 506ms/step - loss: 1.6441 - accuracy: 0.3985\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 1.2857 - accuracy: 0.5197\n",
      "364/364 [==============================] - 183s 501ms/step - loss: 1.6946 - accuracy: 0.3894\n",
      "122/122 [==============================] - 13s 107ms/step - loss: 1.2949 - accuracy: 0.5300\n",
      "364/364 [==============================] - 180s 491ms/step - loss: 1.5657 - accuracy: 0.4246\n",
      "122/122 [==============================] - 13s 103ms/step - loss: 1.1818 - accuracy: 0.5768\n",
      "364/364 [==============================] - 185s 505ms/step - loss: 1.6395 - accuracy: 0.4031\n",
      "122/122 [==============================] - 13s 106ms/step - loss: 1.3615 - accuracy: 0.5059\n",
      "364/364 [==============================] - 380s 1s/step - loss: 1.7310 - accuracy: 0.3738\n",
      "122/122 [==============================] - 31s 252ms/step - loss: 1.2701 - accuracy: 0.5462\n",
      "364/364 [==============================] - 399s 1s/step - loss: 1.8308 - accuracy: 0.3209\n",
      "122/122 [==============================] - 34s 276ms/step - loss: 1.4961 - accuracy: 0.4692\n",
      "364/364 [==============================] - 408s 1s/step - loss: 1.9186 - accuracy: 0.2883\n",
      "122/122 [==============================] - 33s 267ms/step - loss: 1.3829 - accuracy: 0.4861\n",
      "364/364 [==============================] - 428s 1s/step - loss: 1.8795 - accuracy: 0.3050\n",
      "122/122 [==============================] - 35s 289ms/step - loss: 1.4449 - accuracy: 0.4714\n",
      "364/364 [==============================] - 426s 1s/step - loss: 1.7814 - accuracy: 0.3487\n",
      "122/122 [==============================] - 35s 288ms/step - loss: 1.3845 - accuracy: 0.4891\n",
      "364/364 [==============================] - 423s 1s/step - loss: 1.7855 - accuracy: 0.3408\n",
      "122/122 [==============================] - 35s 289ms/step - loss: 1.3540 - accuracy: 0.5109\n",
      "364/364 [==============================] - 434s 1s/step - loss: 1.6515 - accuracy: 0.4006\n",
      "122/122 [==============================] - 38s 310ms/step - loss: 1.2665 - accuracy: 0.5507\n",
      "364/364 [==============================] - 427s 1s/step - loss: 1.7555 - accuracy: 0.3577\n",
      "122/122 [==============================] - 35s 282ms/step - loss: 1.3382 - accuracy: 0.5234\n",
      "364/364 [==============================] - 436s 1s/step - loss: 1.7177 - accuracy: 0.3691\n",
      "122/122 [==============================] - 35s 287ms/step - loss: 1.3287 - accuracy: 0.5267\n",
      "364/364 [==============================] - 431s 1s/step - loss: 1.6381 - accuracy: 0.4071\n",
      "122/122 [==============================] - 36s 291ms/step - loss: 1.3113 - accuracy: 0.5194\n",
      "364/364 [==============================] - 387s 1s/step - loss: 1.7337 - accuracy: 0.3650\n",
      "122/122 [==============================] - 31s 255ms/step - loss: 1.2565 - accuracy: 0.5384\n",
      "364/364 [==============================] - 439s 1s/step - loss: 1.6025 - accuracy: 0.4160\n",
      "122/122 [==============================] - 36s 290ms/step - loss: 1.2648 - accuracy: 0.5464\n",
      "364/364 [==============================] - 121s 331ms/step - loss: 1.8557 - accuracy: 0.3081\n",
      "122/122 [==============================] - 6s 50ms/step - loss: 1.4443 - accuracy: 0.4782\n",
      "364/364 [==============================] - 123s 335ms/step - loss: 1.9535 - accuracy: 0.2635\n",
      "122/122 [==============================] - 6s 50ms/step - loss: 1.4949 - accuracy: 0.4641\n",
      "364/364 [==============================] - 117s 318ms/step - loss: 1.9210 - accuracy: 0.2938\n",
      "122/122 [==============================] - 7s 52ms/step - loss: 1.5139 - accuracy: 0.4480\n",
      "364/364 [==============================] - 118s 323ms/step - loss: 2.0506 - accuracy: 0.2425\n",
      "122/122 [==============================] - 6s 49ms/step - loss: 1.5830 - accuracy: 0.4194\n",
      "364/364 [==============================] - 113s 309ms/step - loss: 1.8853 - accuracy: 0.3068\n",
      "122/122 [==============================] - 6s 50ms/step - loss: 1.4192 - accuracy: 0.4852\n",
      "364/364 [==============================] - 118s 322ms/step - loss: 1.9834 - accuracy: 0.2723\n",
      "122/122 [==============================] - 6s 49ms/step - loss: 1.5630 - accuracy: 0.4347\n",
      "364/364 [==============================] - 113s 309ms/step - loss: 1.7259 - accuracy: 0.3750\n",
      "122/122 [==============================] - 6s 51ms/step - loss: 1.3452 - accuracy: 0.5031\n",
      "364/364 [==============================] - 98s 254ms/step - loss: 1.7841 - accuracy: 0.3435\n",
      "122/122 [==============================] - 5s 40ms/step - loss: 1.4671 - accuracy: 0.4876\n",
      "364/364 [==============================] - 100s 271ms/step - loss: 1.6665 - accuracy: 0.4007\n",
      "122/122 [==============================] - 5s 41ms/step - loss: 1.2298 - accuracy: 0.5573\n",
      "364/364 [==============================] - 94s 257ms/step - loss: 1.6407 - accuracy: 0.4058\n",
      "122/122 [==============================] - 6s 47ms/step - loss: 1.2394 - accuracy: 0.5501\n",
      "364/364 [==============================] - 121s 329ms/step - loss: 1.7990 - accuracy: 0.3469\n",
      "122/122 [==============================] - 6s 51ms/step - loss: 1.5067 - accuracy: 0.4606\n",
      "364/364 [==============================] - 123s 334ms/step - loss: 1.7455 - accuracy: 0.3565\n",
      "122/122 [==============================] - 6s 50ms/step - loss: 1.3451 - accuracy: 0.5265\n",
      "364/364 [==============================] - 186s 507ms/step - loss: 2.0021 - accuracy: 0.2529\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 1.5673 - accuracy: 0.4375\n",
      "364/364 [==============================] - 185s 505ms/step - loss: 1.9595 - accuracy: 0.2790\n",
      "122/122 [==============================] - 13s 107ms/step - loss: 1.5501 - accuracy: 0.4545\n",
      "364/364 [==============================] - 182s 498ms/step - loss: 1.9605 - accuracy: 0.2482\n",
      "122/122 [==============================] - 13s 103ms/step - loss: 1.6120 - accuracy: 0.4106\n",
      "364/364 [==============================] - 183s 499ms/step - loss: 1.8954 - accuracy: 0.2998\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 1.4815 - accuracy: 0.4722\n",
      "364/364 [==============================] - 182s 495ms/step - loss: 1.7787 - accuracy: 0.3617\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 1.5911 - accuracy: 0.4314\n",
      "364/364 [==============================] - 155s 424ms/step - loss: 1.7737 - accuracy: 0.3521\n",
      "122/122 [==============================] - 11s 88ms/step - loss: 1.4060 - accuracy: 0.4854\n",
      "364/364 [==============================] - 188s 514ms/step - loss: 1.7978 - accuracy: 0.3497\n",
      "122/122 [==============================] - 13s 109ms/step - loss: 1.4450 - accuracy: 0.4758\n",
      "364/364 [==============================] - 186s 510ms/step - loss: 1.7286 - accuracy: 0.3749\n",
      "122/122 [==============================] - 14s 110ms/step - loss: 1.2874 - accuracy: 0.5332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 187s 511ms/step - loss: 1.6958 - accuracy: 0.3757\n",
      "122/122 [==============================] - 14s 110ms/step - loss: 1.2661 - accuracy: 0.5527\n",
      "364/364 [==============================] - 186s 509ms/step - loss: 1.6238 - accuracy: 0.4102\n",
      "122/122 [==============================] - 13s 108ms/step - loss: 1.2394 - accuracy: 0.5506\n",
      "364/364 [==============================] - 188s 515ms/step - loss: 1.8209 - accuracy: 0.3328\n",
      "122/122 [==============================] - 14s 111ms/step - loss: 1.4133 - accuracy: 0.4856\n",
      "364/364 [==============================] - 184s 504ms/step - loss: 1.6515 - accuracy: 0.4019\n",
      "122/122 [==============================] - 13s 104ms/step - loss: 1.2786 - accuracy: 0.5317\n",
      "364/364 [==============================] - 413s 1s/step - loss: 1.8901 - accuracy: 0.2899\n",
      "122/122 [==============================] - 33s 273ms/step - loss: 1.5226 - accuracy: 0.4216\n",
      "364/364 [==============================] - 422s 1s/step - loss: 1.9788 - accuracy: 0.2585\n",
      "122/122 [==============================] - 34s 278ms/step - loss: 1.6033 - accuracy: 0.4270\n",
      "364/364 [==============================] - 375s 1s/step - loss: 1.8642 - accuracy: 0.3170\n",
      "122/122 [==============================] - 30s 248ms/step - loss: 1.3684 - accuracy: 0.5124\n",
      "364/364 [==============================] - 384s 1s/step - loss: 1.9349 - accuracy: 0.2848\n",
      "122/122 [==============================] - 30s 248ms/step - loss: 1.6067 - accuracy: 0.4140\n",
      "364/364 [==============================] - 405s 1s/step - loss: 1.9302 - accuracy: 0.2890\n",
      "122/122 [==============================] - 34s 281ms/step - loss: 1.4780 - accuracy: 0.4677\n",
      "364/364 [==============================] - 423s 1s/step - loss: 1.7534 - accuracy: 0.3560\n",
      "122/122 [==============================] - 34s 278ms/step - loss: 1.3024 - accuracy: 0.5249\n",
      "364/364 [==============================] - 422s 1s/step - loss: 1.8442 - accuracy: 0.3207\n",
      "122/122 [==============================] - 34s 279ms/step - loss: 1.4132 - accuracy: 0.4869\n",
      "364/364 [==============================] - 421s 1s/step - loss: 1.7557 - accuracy: 0.3618\n",
      "122/122 [==============================] - 34s 276ms/step - loss: 1.3472 - accuracy: 0.5270\n",
      "364/364 [==============================] - 425s 1s/step - loss: 1.5731 - accuracy: 0.4275\n",
      "122/122 [==============================] - 34s 279ms/step - loss: 1.2495 - accuracy: 0.5403\n",
      "364/364 [==============================] - 423s 1s/step - loss: 1.7730 - accuracy: 0.3492\n",
      "122/122 [==============================] - 34s 275ms/step - loss: 1.2854 - accuracy: 0.5416\n",
      "364/364 [==============================] - 427s 1s/step - loss: 1.6447 - accuracy: 0.3970\n",
      "122/122 [==============================] - 35s 280ms/step - loss: 1.2306 - accuracy: 0.5611\n",
      "364/364 [==============================] - 430s 1s/step - loss: 1.8006 - accuracy: 0.3331\n",
      "122/122 [==============================] - 34s 280ms/step - loss: 1.4001 - accuracy: 0.5052\n",
      "486/486 [==============================] - 137s 279ms/step - loss: 1.6413 - accuracy: 0.4077\n",
      "0.542177751660347\n",
      "{'dropout': 0.1,\n",
      " 'filters': 32,\n",
      " 'neurons': 64}\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'filters': [32, 64, 128],\n",
    "    'neurons': [32, 64, 128],\n",
    "    'dropout': [0, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "model = KerasClassifier(\n",
    "    build_fn=build_model,\n",
    "    verbose=VERBOSITY\n",
    ")\n",
    "\n",
    "grid_search_cv = GridSearchCV(\n",
    "    model,\n",
    "    param_grid=param_grid,\n",
    "    verbose=VERBOSITY,\n",
    "    cv=4\n",
    ")\n",
    "\n",
    "grid_result = grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(grid_result.best_score_)\n",
    "\n",
    "pprint.pprint(\n",
    "    grid_result.best_params_,\n",
    "    width=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-15T10:02:27.228265Z",
     "start_time": "2023-04-15T10:02:27.081608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-16 18:54:27.387323: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 67s 544ms/step - loss: 2.1263 - accuracy: 0.2043 - val_loss: 1.9073 - val_accuracy: 0.2951\n",
      "Epoch 2/100\n",
      "121/121 [==============================] - 65s 533ms/step - loss: 1.9059 - accuracy: 0.2905 - val_loss: 1.7769 - val_accuracy: 0.3281\n",
      "Epoch 3/100\n",
      "121/121 [==============================] - 65s 536ms/step - loss: 1.8421 - accuracy: 0.3095 - val_loss: 1.7069 - val_accuracy: 0.3688\n",
      "Epoch 4/100\n",
      "121/121 [==============================] - 65s 535ms/step - loss: 1.7658 - accuracy: 0.3371 - val_loss: 1.7570 - val_accuracy: 0.3402\n",
      "Epoch 5/100\n",
      "121/121 [==============================] - 65s 536ms/step - loss: 1.7586 - accuracy: 0.3339 - val_loss: 1.6680 - val_accuracy: 0.3657\n",
      "Epoch 6/100\n",
      "121/121 [==============================] - 66s 546ms/step - loss: 1.7199 - accuracy: 0.3529 - val_loss: 1.6674 - val_accuracy: 0.3693\n",
      "Epoch 7/100\n",
      "121/121 [==============================] - 64s 532ms/step - loss: 1.6983 - accuracy: 0.3600 - val_loss: 1.6371 - val_accuracy: 0.3814\n",
      "Epoch 8/100\n",
      "121/121 [==============================] - 65s 537ms/step - loss: 1.6794 - accuracy: 0.3675 - val_loss: 1.7130 - val_accuracy: 0.3618\n",
      "Epoch 9/100\n",
      "121/121 [==============================] - 65s 537ms/step - loss: 1.6487 - accuracy: 0.3781 - val_loss: 1.6245 - val_accuracy: 0.3827\n",
      "Epoch 10/100\n",
      "121/121 [==============================] - 64s 530ms/step - loss: 1.6576 - accuracy: 0.3811 - val_loss: 1.5890 - val_accuracy: 0.4074\n",
      "Epoch 11/100\n",
      "121/121 [==============================] - 65s 537ms/step - loss: 1.6122 - accuracy: 0.3910 - val_loss: 1.5858 - val_accuracy: 0.4159\n",
      "Epoch 12/100\n",
      "121/121 [==============================] - 64s 525ms/step - loss: 1.6062 - accuracy: 0.3972 - val_loss: 1.5581 - val_accuracy: 0.4141\n",
      "Epoch 13/100\n",
      "121/121 [==============================] - 65s 537ms/step - loss: 1.5765 - accuracy: 0.4020 - val_loss: 1.5414 - val_accuracy: 0.4218\n",
      "Epoch 14/100\n",
      "121/121 [==============================] - 65s 535ms/step - loss: 1.5762 - accuracy: 0.4100 - val_loss: 1.5229 - val_accuracy: 0.4257\n",
      "Epoch 15/100\n",
      "121/121 [==============================] - 65s 535ms/step - loss: 1.5566 - accuracy: 0.4128 - val_loss: 1.5133 - val_accuracy: 0.4321\n",
      "Epoch 16/100\n",
      "121/121 [==============================] - 65s 536ms/step - loss: 1.5621 - accuracy: 0.4132 - val_loss: 1.5154 - val_accuracy: 0.4218\n",
      "Epoch 17/100\n",
      "121/121 [==============================] - 65s 537ms/step - loss: 1.5417 - accuracy: 0.4139 - val_loss: 1.4768 - val_accuracy: 0.4471\n",
      "Epoch 18/100\n",
      "121/121 [==============================] - 65s 537ms/step - loss: 1.5314 - accuracy: 0.4232 - val_loss: 1.5136 - val_accuracy: 0.4257\n",
      "Epoch 19/100\n",
      "121/121 [==============================] - 65s 541ms/step - loss: 1.5346 - accuracy: 0.4174 - val_loss: 1.4820 - val_accuracy: 0.4288\n",
      "Epoch 20/100\n",
      "121/121 [==============================] - 64s 529ms/step - loss: 1.5154 - accuracy: 0.4219 - val_loss: 1.4636 - val_accuracy: 0.4497\n",
      "Epoch 21/100\n",
      "121/121 [==============================] - 65s 538ms/step - loss: 1.5266 - accuracy: 0.4219 - val_loss: 1.4848 - val_accuracy: 0.4301\n",
      "Epoch 22/100\n",
      "121/121 [==============================] - 65s 536ms/step - loss: 1.5210 - accuracy: 0.4305 - val_loss: 1.5127 - val_accuracy: 0.4334\n",
      "Epoch 23/100\n",
      "121/121 [==============================] - 64s 532ms/step - loss: 1.4996 - accuracy: 0.4318 - val_loss: 1.4423 - val_accuracy: 0.4525\n",
      "Epoch 24/100\n",
      "121/121 [==============================] - 65s 535ms/step - loss: 1.5061 - accuracy: 0.4226 - val_loss: 1.4332 - val_accuracy: 0.4654\n",
      "Epoch 25/100\n",
      "121/121 [==============================] - 64s 532ms/step - loss: 1.4889 - accuracy: 0.4411 - val_loss: 1.5157 - val_accuracy: 0.4316\n",
      "Epoch 26/100\n",
      "121/121 [==============================] - 64s 527ms/step - loss: 1.5026 - accuracy: 0.4294 - val_loss: 1.4461 - val_accuracy: 0.4589\n",
      "Epoch 27/100\n",
      "121/121 [==============================] - 64s 528ms/step - loss: 1.4803 - accuracy: 0.4330 - val_loss: 1.4043 - val_accuracy: 0.4764\n",
      "Epoch 28/100\n",
      "121/121 [==============================] - 65s 541ms/step - loss: 1.4788 - accuracy: 0.4446 - val_loss: 1.4474 - val_accuracy: 0.4486\n",
      "Epoch 29/100\n",
      "121/121 [==============================] - 66s 542ms/step - loss: 1.4803 - accuracy: 0.4349 - val_loss: 1.4176 - val_accuracy: 0.4641\n",
      "Epoch 30/100\n",
      "121/121 [==============================] - 65s 540ms/step - loss: 1.4605 - accuracy: 0.4452 - val_loss: 1.4129 - val_accuracy: 0.4648\n",
      "Epoch 31/100\n",
      "121/121 [==============================] - 64s 531ms/step - loss: 1.4740 - accuracy: 0.4431 - val_loss: 1.4191 - val_accuracy: 0.4489\n",
      "Epoch 32/100\n",
      "121/121 [==============================] - 64s 526ms/step - loss: 1.4653 - accuracy: 0.4476 - val_loss: 1.4155 - val_accuracy: 0.4705\n",
      "Epoch 33/100\n",
      "121/121 [==============================] - 64s 528ms/step - loss: 1.4670 - accuracy: 0.4430 - val_loss: 1.4108 - val_accuracy: 0.4582\n",
      "Epoch 34/100\n",
      "121/121 [==============================] - 65s 539ms/step - loss: 1.4619 - accuracy: 0.4423 - val_loss: 1.4173 - val_accuracy: 0.4669\n",
      "Epoch 35/100\n",
      "121/121 [==============================] - 65s 538ms/step - loss: 1.4340 - accuracy: 0.4548 - val_loss: 1.4353 - val_accuracy: 0.4641\n",
      "Epoch 36/100\n",
      "121/121 [==============================] - 64s 525ms/step - loss: 1.4489 - accuracy: 0.4476 - val_loss: 1.3733 - val_accuracy: 0.4785\n",
      "Epoch 37/100\n",
      "121/121 [==============================] - 64s 529ms/step - loss: 1.4507 - accuracy: 0.4500 - val_loss: 1.4343 - val_accuracy: 0.4692\n",
      "Epoch 38/100\n",
      "121/121 [==============================] - 66s 546ms/step - loss: 1.4415 - accuracy: 0.4539 - val_loss: 1.4338 - val_accuracy: 0.4545\n",
      "Epoch 39/100\n",
      "121/121 [==============================] - 65s 538ms/step - loss: 1.4519 - accuracy: 0.4467 - val_loss: 1.3936 - val_accuracy: 0.4767\n",
      "Epoch 40/100\n",
      "121/121 [==============================] - 65s 539ms/step - loss: 1.4277 - accuracy: 0.4555 - val_loss: 1.4013 - val_accuracy: 0.4746\n",
      "Epoch 41/100\n",
      "121/121 [==============================] - 65s 540ms/step - loss: 1.4166 - accuracy: 0.4549 - val_loss: 1.4132 - val_accuracy: 0.4615\n",
      "Epoch 42/100\n",
      "121/121 [==============================] - 65s 538ms/step - loss: 1.4288 - accuracy: 0.4608 - val_loss: 1.3971 - val_accuracy: 0.4847\n",
      "Epoch 43/100\n",
      "121/121 [==============================] - 65s 538ms/step - loss: 1.4198 - accuracy: 0.4606 - val_loss: 1.3794 - val_accuracy: 0.4806\n",
      "Epoch 44/100\n",
      "121/121 [==============================] - 67s 549ms/step - loss: 1.4132 - accuracy: 0.4611 - val_loss: 1.3972 - val_accuracy: 0.4803\n",
      "Epoch 45/100\n",
      "121/121 [==============================] - 64s 531ms/step - loss: 1.4073 - accuracy: 0.4622 - val_loss: 1.3694 - val_accuracy: 0.4867\n",
      "Epoch 46/100\n",
      "121/121 [==============================] - 65s 537ms/step - loss: 1.4029 - accuracy: 0.4695 - val_loss: 1.3586 - val_accuracy: 0.4790\n",
      "Epoch 47/100\n",
      "121/121 [==============================] - 65s 539ms/step - loss: 1.3965 - accuracy: 0.4698 - val_loss: 1.3571 - val_accuracy: 0.4878\n",
      "Epoch 48/100\n",
      "121/121 [==============================] - 64s 526ms/step - loss: 1.3873 - accuracy: 0.4671 - val_loss: 1.3495 - val_accuracy: 0.4896\n",
      "Epoch 49/100\n",
      "121/121 [==============================] - 65s 539ms/step - loss: 1.3903 - accuracy: 0.4743 - val_loss: 1.3931 - val_accuracy: 0.4790\n",
      "Epoch 50/100\n",
      "121/121 [==============================] - 65s 536ms/step - loss: 1.3873 - accuracy: 0.4605 - val_loss: 1.3777 - val_accuracy: 0.4708\n",
      "Epoch 51/100\n",
      "121/121 [==============================] - 64s 531ms/step - loss: 1.3838 - accuracy: 0.4645 - val_loss: 1.3362 - val_accuracy: 0.4901\n",
      "Epoch 52/100\n",
      "121/121 [==============================] - 65s 541ms/step - loss: 1.3965 - accuracy: 0.4706 - val_loss: 1.3431 - val_accuracy: 0.4829\n",
      "Epoch 53/100\n",
      "121/121 [==============================] - 64s 531ms/step - loss: 1.3989 - accuracy: 0.4633 - val_loss: 1.3498 - val_accuracy: 0.4932\n",
      "Epoch 54/100\n",
      "121/121 [==============================] - 65s 539ms/step - loss: 1.4005 - accuracy: 0.4634 - val_loss: 1.3710 - val_accuracy: 0.4695\n",
      "Epoch 55/100\n",
      "121/121 [==============================] - 64s 526ms/step - loss: 1.3787 - accuracy: 0.4742 - val_loss: 1.3701 - val_accuracy: 0.4829\n",
      "Epoch 56/100\n",
      "121/121 [==============================] - 65s 533ms/step - loss: 1.3860 - accuracy: 0.4725 - val_loss: 1.3331 - val_accuracy: 0.4836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "121/121 [==============================] - 66s 544ms/step - loss: 1.3841 - accuracy: 0.4715 - val_loss: 1.3521 - val_accuracy: 0.4844\n",
      "Epoch 58/100\n",
      "121/121 [==============================] - 63s 517ms/step - loss: 1.3900 - accuracy: 0.4645 - val_loss: 1.3122 - val_accuracy: 0.4965\n",
      "Epoch 59/100\n",
      "121/121 [==============================] - 65s 537ms/step - loss: 1.3845 - accuracy: 0.4743 - val_loss: 1.4202 - val_accuracy: 0.4710\n",
      "Epoch 60/100\n",
      "121/121 [==============================] - 64s 525ms/step - loss: 1.3799 - accuracy: 0.4735 - val_loss: 1.3420 - val_accuracy: 0.4836\n",
      "Epoch 61/100\n",
      "121/121 [==============================] - 65s 534ms/step - loss: 1.3922 - accuracy: 0.4709 - val_loss: 1.3302 - val_accuracy: 0.4857\n",
      "Epoch 62/100\n",
      "121/121 [==============================] - 65s 538ms/step - loss: 1.3708 - accuracy: 0.4718 - val_loss: 1.3291 - val_accuracy: 0.4932\n",
      "Epoch 63/100\n",
      "121/121 [==============================] - 66s 546ms/step - loss: 1.3735 - accuracy: 0.4753 - val_loss: 1.3798 - val_accuracy: 0.4744\n",
      "Epoch 64/100\n",
      "121/121 [==============================] - 62s 508ms/step - loss: 1.3758 - accuracy: 0.4737 - val_loss: 1.3570 - val_accuracy: 0.4818\n",
      "Epoch 65/100\n",
      "121/121 [==============================] - 64s 528ms/step - loss: 1.3694 - accuracy: 0.4749 - val_loss: 1.3089 - val_accuracy: 0.4999\n",
      "Epoch 66/100\n",
      "121/121 [==============================] - 64s 530ms/step - loss: 1.3680 - accuracy: 0.4769 - val_loss: 1.3628 - val_accuracy: 0.4842\n",
      "Epoch 67/100\n",
      "121/121 [==============================] - 64s 531ms/step - loss: 1.3600 - accuracy: 0.4738 - val_loss: 1.3115 - val_accuracy: 0.5017\n",
      "Epoch 68/100\n",
      "121/121 [==============================] - 64s 527ms/step - loss: 1.3518 - accuracy: 0.4805 - val_loss: 1.3005 - val_accuracy: 0.4958\n",
      "Epoch 69/100\n",
      "121/121 [==============================] - 64s 524ms/step - loss: 1.3523 - accuracy: 0.4806 - val_loss: 1.3175 - val_accuracy: 0.4901\n",
      "Epoch 70/100\n",
      "121/121 [==============================] - 63s 519ms/step - loss: 1.3692 - accuracy: 0.4762 - val_loss: 1.3274 - val_accuracy: 0.4891\n",
      "Epoch 71/100\n",
      "121/121 [==============================] - 63s 524ms/step - loss: 1.3508 - accuracy: 0.4806 - val_loss: 1.3197 - val_accuracy: 0.4919\n",
      "Epoch 72/100\n",
      "121/121 [==============================] - 65s 540ms/step - loss: 1.3501 - accuracy: 0.4888 - val_loss: 1.3370 - val_accuracy: 0.4909\n",
      "Epoch 73/100\n",
      "121/121 [==============================] - 67s 551ms/step - loss: 1.3574 - accuracy: 0.4781 - val_loss: 1.3263 - val_accuracy: 0.4952\n",
      "Epoch 74/100\n",
      "121/121 [==============================] - 68s 560ms/step - loss: 1.3406 - accuracy: 0.4867 - val_loss: 1.3217 - val_accuracy: 0.4988\n",
      "Epoch 75/100\n",
      "121/121 [==============================] - 65s 538ms/step - loss: 1.3534 - accuracy: 0.4864 - val_loss: 1.3124 - val_accuracy: 0.4978\n",
      "Epoch 76/100\n",
      "121/121 [==============================] - 64s 530ms/step - loss: 1.3615 - accuracy: 0.4841 - val_loss: 1.3174 - val_accuracy: 0.5040\n",
      "Epoch 77/100\n",
      "121/121 [==============================] - 65s 539ms/step - loss: 1.3475 - accuracy: 0.4823 - val_loss: 1.2853 - val_accuracy: 0.5063\n",
      "Epoch 78/100\n",
      "121/121 [==============================] - 69s 567ms/step - loss: 1.3557 - accuracy: 0.4856 - val_loss: 1.3302 - val_accuracy: 0.4857\n",
      "Epoch 79/100\n",
      "121/121 [==============================] - 67s 553ms/step - loss: 1.3535 - accuracy: 0.4794 - val_loss: 1.2922 - val_accuracy: 0.5102\n",
      "Epoch 80/100\n",
      "121/121 [==============================] - 73s 607ms/step - loss: 1.3393 - accuracy: 0.4888 - val_loss: 1.2661 - val_accuracy: 0.5169\n",
      "Epoch 81/100\n",
      "121/121 [==============================] - 78s 642ms/step - loss: 1.3373 - accuracy: 0.4827 - val_loss: 1.2775 - val_accuracy: 0.5102\n",
      "Epoch 82/100\n",
      "121/121 [==============================] - 75s 620ms/step - loss: 1.3310 - accuracy: 0.4904 - val_loss: 1.2926 - val_accuracy: 0.5019\n",
      "Epoch 83/100\n",
      "121/121 [==============================] - 69s 569ms/step - loss: 1.3381 - accuracy: 0.4892 - val_loss: 1.2981 - val_accuracy: 0.5055\n",
      "Epoch 84/100\n",
      "121/121 [==============================] - 69s 573ms/step - loss: 1.3237 - accuracy: 0.4894 - val_loss: 1.3003 - val_accuracy: 0.4973\n",
      "Epoch 85/100\n",
      "121/121 [==============================] - 71s 589ms/step - loss: 1.3259 - accuracy: 0.4992 - val_loss: 1.2828 - val_accuracy: 0.5125\n",
      "Epoch 86/100\n",
      "121/121 [==============================] - 71s 586ms/step - loss: 1.3305 - accuracy: 0.4917 - val_loss: 1.2886 - val_accuracy: 0.5094\n",
      "Epoch 87/100\n",
      "121/121 [==============================] - 72s 597ms/step - loss: 1.3182 - accuracy: 0.4915 - val_loss: 1.2760 - val_accuracy: 0.5156\n",
      "Epoch 88/100\n",
      "121/121 [==============================] - 73s 603ms/step - loss: 1.3279 - accuracy: 0.4932 - val_loss: 1.2886 - val_accuracy: 0.5102\n",
      "Epoch 89/100\n",
      "121/121 [==============================] - 76s 625ms/step - loss: 1.3378 - accuracy: 0.4870 - val_loss: 1.2798 - val_accuracy: 0.5094\n",
      "Epoch 90/100\n",
      "121/121 [==============================] - 75s 615ms/step - loss: 1.3118 - accuracy: 0.4994 - val_loss: 1.2750 - val_accuracy: 0.5042\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "model_best = build_model(**grid_result.best_params_)\n",
    "\n",
    "datagen_augment = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    ")\n",
    "\n",
    "\n",
    "history_best = fit_model(\n",
    "    model_best,\n",
    "    datagen_augment,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_history_acc(history_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "446/446 [==============================] - 28s 62ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67      1617\n",
      "           1       0.44      0.44      0.44      1415\n",
      "           2       0.37      0.33      0.35      1479\n",
      "           3       0.36      0.31      0.33      1498\n",
      "           4       0.51      0.44      0.47      1372\n",
      "           5       0.69      0.82      0.75      1467\n",
      "           6       0.55      0.67      0.61      1305\n",
      "           7       0.46      0.56      0.50      1369\n",
      "           8       0.36      0.45      0.40      1406\n",
      "           9       0.43      0.17      0.25      1344\n",
      "\n",
      "    accuracy                           0.49     14272\n",
      "   macro avg       0.48      0.49      0.48     14272\n",
      "weighted avg       0.48      0.49      0.48     14272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "evaluate_model(model_best, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1. What preprocessing techniques did you use? Why?\n",
    "    - Scale image standartized size - 128x128\n",
    "    - Convert each pixel's value to value in range \\[0, 255\\], which represents its darkness\n",
    "2. What data augmentation techniques did you use?\n",
    "    - Randomly:\n",
    "        - Rotate image up to 10 degree\n",
    "        - Flip image along vertical axis (horizontally)\n",
    "        - Move image by x or y up to 10%\n",
    "3. Describe the fine-tuning process and how you reached your final CNN model.\n",
    "    - I derived the most valuable hyperparameters of CNN:\n",
    "        - Max filters count\n",
    "        - Dense layer's neurons count\n",
    "        - Dropout layer's probability\n",
    "    - I also used \"adam\" optimizer to tune learning rate\n",
    "4. What techniques did you use to improve models performance other than data augmentation\n",
    "    - *Answer*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Credit approval (15 points)\n",
    "\n",
    "Credit approval is necessary to assess an individual's creditworthiness and determine their eligibility for loans, credit cards, and other financial products. It helps lenders to evaluate the borrower's ability to repay the loan, their credit history, and other financial obligations.\n",
    "Credit approval is important for both lenders and borrowers because it enables lenders to manage their risk and make informed lending decisions while ensuring that borrowers can obtain financing on fair and reasonable terms.\n",
    "\n",
    "In many credit approval applications, it is crucial for the model to be interpretable. This means that the model's inner workings and decision-making process can be easily understood and explained by humans. An interpretable model can help to build trust in the model's output, provide transparency in the decision-making process, and enable regulators to monitor and audit the model's performance. \n",
    "\n",
    "## What you need to do\n",
    "\n",
    "For the `loan_data.csv` data, predict if the bank should give a loan or not.\n",
    "\n",
    "- Fine-tune a decision tree on the data\n",
    "- Fine-tune a random forest on the data\n",
    "- Compare their performance\n",
    "- Visualize your DT and one of the trees from the RF\n",
    "\n",
    "For evaluating your models, do $80/20$ train test split.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Apply DTs, and RFs to solve a classification problem (basic training, validation, testing. 50%\n",
    "- Fine-tune to determine the optimal model architecture. 20%\n",
    "- Evaluate and compare the performance of different models. 10%\n",
    "- Visualise the models. 20%\n",
    "\n",
    "\n",
    "### Data\n",
    "- `credit.policy`: Whether the customer meets the credit underwriting criteria.\n",
    "- `purpose`: The purpose of the loan.\n",
    "- `int.rate`: The interest rate of the loan.\n",
    "- `installment`: The monthly installments owed by the borrower if the loan is funded.\n",
    "- `log.annual.inc`: The natural logarithm of the self-reported annual income of the borrower.\n",
    "- `dti`: The debt-to-income ratio of the borrower.\n",
    "- `fico`: The FICO credit score of the borrower.\n",
    "- `days.with.cr.line`: The number of days the borrower has had a credit line.\n",
    "- `revol.bal`: The borrower's revolving balance.\n",
    "- `revol.util`: The borrower's revolving line utilization rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T12:20:05.167332Z",
     "start_time": "2023-04-11T12:20:05.130066Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Implement task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1. How did the DT compare to the RF in performance? Why?\n",
    "    - *Answer*\n",
    "2. After fine-tuning, how does the max depth in DT compare to RF? Why?\n",
    "    - *Answer*\n",
    "3. What is ensemble learning? What are its pros and cons?\n",
    "    - *Answer*\n",
    "4. Briefly explain 2 types of boosting methods and 2 types of bagging methods.\n",
    "Which of these categories does RF fall under?\n",
    "    - *Answer*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
